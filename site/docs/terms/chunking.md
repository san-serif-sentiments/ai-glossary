<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# chunking

**Aliases:** document chunking, segmentation
**Categories:** Retrieval & RAG
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers
**Part of speech:** `process`
**Status:** <span class="status-chip status-draft">Draft</span> (Last reviewed: 2024-11-01)

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Validate retrieval quality using the evaluation guidance referenced in this entry.
- Ensure knowledge sources named here appear in your data governance inventory.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Splitting source documents into manageable pieces before indexing or feeding them to models.

## Long definition
Chunking divides large documents, transcripts, or code repositories into smaller segments that fit within a modelâ€™s context window and maintain topical coherence. Effective chunking balances granularity: slices must be large enough to preserve meaning yet small enough to avoid wasting tokens on irrelevant text. Techniques include fixed-length windows, semantic segmentation based on headings, and overlap strategies that keep shared context between adjacent chunks. In retrieval-augmented generation systems, chunking quality directly influences whether relevant passages appear in the prompt and whether citations map to recognizable sections. Engineers document chunking parameters alongside embedding models so they can reproduce indexes and evaluate recall. Governance teams assess chunking for privacy and intellectual property concerns, ensuring sensitive data is not inadvertently duplicated or exposed beyond its intended audience when recombining chunks.

## Audience perspectives
- **Exec:** Chunking is how we slice big documents so the AI can reason over them without losing the thread.
- **Engineer:** Segmentation pipeline defining window size, overlap, and heuristics that prepare content for embedding and retrieval.

## Examples
**Do**
- Tune chunk size and overlap per document type and validate with retrieval relevance tests.

**Don't**
- Use a single chunking strategy for code, policy docs, and conversations without benchmarking.

## Governance
- **NIST RMF tags:** data_quality, privacy
- **Risk notes:** Poor chunking can duplicate sensitive data or break context needed for accurate, compliant answers.

## Relationships
- **Broader:** data preprocessing
- **Narrower:** semantic chunking
- **Related:** retrieval, vector store, reranking

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'chunking'.

## Citations
- [Hugging Face Glossary](https://huggingface.co/docs/transformers/en/glossary)
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary)
- [Wikipedia AI Glossary](https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence)

_License: CC BY-SA 4.0_

_Source file: `data/terms/chunking.yml`_
