<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# agentic ai

**Aliases:** ai agents, autonomous agent
**Categories:** Agents & Tooling
**Roles:** Engineering & Platform, Product & Program Managers
**Part of speech:** `concept`
**Status:** <span class="status-chip status-reviewed">Reviewed</span> (Last reviewed: 2025-09-28)

## Role takeaways
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Audit exposed tools against the safeguards described and document approval paths.
- Test hand-offs with human reviewers to confirm the safety expectations captured here are met.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Systems that plan, act, and iterate with minimal human prompts by chaining model calls and tools.

## Long definition
Agentic AI describes architectures where models make decisions about what actions to take next, often using planning loops, tool calls, and memory to pursue a goal. Unlike single-shot prompting, agentic systems break work into steps, call APIs, and reflect on intermediate results before proceeding. They power use cases like research assistants, workflow automation, and incident triage bots. Engineers combine language models with planners, vector memories, and policy checks to maintain control. Product teams set guardrails on autonomy levels, defining when humans approve steps or review logs. Governance stakeholders focus on accountability, ensuring agent actions are auditable, reversible, and aligned with policy. Because agentic AI increases the surface area for safety incidents or costly loops, monitoring and termination criteria are essential. Investing in agent design principles helps organizations harness automation without losing visibility or violating compliance commitments.

## Audience perspectives
- **Exec:** Agentic AI strings tasks together so the assistant can take initiative instead of waiting for every instruction.
- **Engineer:** Orchestrate planning, tool invocation, and memory components around an LLM to execute multi-step objectives.

## Examples
**Do**
- Define termination conditions and escalation triggers before enabling autonomous execution.

**Don't**
- Allow agents unfettered access to production systems without audit trails or throttling.

## Governance
- **NIST RMF tags:** accountability, risk_management
- **Risk notes:** Autonomous loops can drift from intent or amplify harmful behaviors if oversight is weak.

## Relationships
- **Broader:** generative ai
- **Narrower:** tool use, retrieval-augmented generation
- **Related:** guardrails, system prompt, incident response

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'agentic ai'.

## Citations
- [NIST AI RMF Glossary](https://airc.nist.gov/glossary/)
- [Hugging Face Glossary](https://huggingface.co/docs/transformers/en/glossary)
- [UK POST AI Glossary](https://post.parliament.uk/publications/artificial-intelligence/ai-glossary/)

_License: CC BY-SA 4.0_

_Source file: `data/terms/agentic-ai.yml`_
