<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# privacy impact assessment

**Aliases:** pia, data protection impact assessment
**Categories:** Governance & Risk
**Roles:** Legal & Compliance, Policy & Risk, Product & Program Managers, Security & Trust
**Part of speech:** `process`
**Status:** <span class="status-chip status-draft">Draft</span> (Last reviewed: 2024-11-03)

## Role takeaways
- **Legal & Compliance:** Assess contractual and regulatory obligations tied to this term.
- **Policy & Risk:** Map the definition to governance controls and review checklists.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.
- **Security & Trust:** Plan monitoring and abuse prevention scenarios influenced by this term.

## Practice & apply
- Map this term to the governance dashboard and record accountable owners in the backlog.
- Review current regulatory guidance or internal policy notes linked from the resources page before sign-off.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Structured review that evaluates how a system collects, uses, and safeguards personal data.

## Long definition
A privacy impact assessment (PIA) identifies and mitigates privacy risks before launching or materially changing a product, dataset, or model. The process documents data sources, lawful bases, retention policies, third-party sharing, and safeguards such as encryption or differential privacy. PIAs often involve cross-functional stakeholders—legal, security, engineering, product, and compliance—to ensure controls meet regulatory requirements like GDPR, CCPA, or sector-specific rules. For AI systems, PIAs examine training data provenance, prompt logging, telemetry retention, and user disclosure obligations. Findings feed into risk registers, customer communications, and incident response plans. Conducting PIAs early reduces costly redesigns and strengthens trust with regulators, customers, and internal reviewers.

## Audience perspectives
- **Exec:** A PIA is the privacy due diligence that keeps AI launches compliant and defensible.
- **Engineer:** Provide technical details on data flows, storage, and safeguards so legal can verify privacy controls.

## Examples
**Do**
- Trigger a PIA whenever new personal data sources or model capabilities are introduced.
- Track mitigation tasks from the PIA in your product backlog until resolved.

**Don't**
- Treat PIAs as paperwork; revisit them after model updates or incidents.
- Launch features that collect personal data without completing the assessment.

## Governance
- **NIST RMF tags:** privacy, documentation
- **Risk notes:** Skipping PIAs can violate legal obligations, resulting in fines or mandatory shutdowns.

## Relationships
- **Broader:** model governance
- **Related:** differential privacy, incident response, guardrails

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'privacy impact assessment'.

## Citations
- [NIST AI RMF Glossary](https://airc.nist.gov/glossary/)
- [UK POST AI Glossary](https://post.parliament.uk/publications/artificial-intelligence/ai-glossary/)
- [Stanford HAI Brief Definitions](https://hai.stanford.edu/news/brief-definitions)

_License: CC BY-SA 4.0_

_Source file: `data/terms/privacy-impact-assessment.yml`_
