<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# generative ai

**Aliases:** genai, generative artificial intelligence
**Categories:** Foundations
**Roles:** Communications & Enablement, Policy & Risk, Product & Program Managers
**Part of speech:** `concept`
**Status:** `draft` (Last reviewed: 2024-11-01)

## Short definition
Family of models that produce new content—text, images, code—rather than only making predictions.

## Long definition
Generative AI refers to systems that create novel outputs such as text, images, audio, or code by learning patterns from large training corpora. Foundation models like GPT, diffusion models, and multimodal architectures power these experiences by predicting the next token or pixel based on context. Organizations adopt generative AI for drafting, summarization, design, simulation, and synthetic data generation. The technology amplifies creativity and productivity but introduces unique risks, including hallucinations, intellectual property exposure, and safety concerns. Product leaders evaluate generative AI opportunities alongside guardrails, retrieval augmentation, and review workflows to keep outputs trustworthy. Engineers maintain the pipelines that tokenize data, manage prompts, deploy models, and monitor usage at scale. Governance teams coordinate policies covering responsible use, content moderation, privacy, and transparency. Understanding generative AI provides the context for more specialized concepts in this glossary, from attention mechanisms to red teaming.

## Audience perspectives
- **Exec:** Generative AI is the class of systems that draft content on demand, automating creative and analytical tasks.
- **Engineer:** Models that learn probability distributions over complex data and sample from them to produce new artifacts.

## Examples
**Do**
- Pair generative AI deployments with clear disclosure and feedback channels for users.

**Don't**
- Launch generative features without documenting data sources, evaluation, and risk mitigations.

## Governance
- **NIST RMF tags:** transparency, risk_management
- **Risk notes:** Uncontrolled generative systems can leak sensitive data, create misleading content, or breach intellectual property.

## Relationships
- **Broader:** artificial intelligence
- **Narrower:** retrieval-augmented generation, hallucination, decoding
- **Related:** attention, prompt engineering, guardrails

## Citations
- [NIST AI RMF Glossary](https://airc.nist.gov/glossary/)
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary)
- [Wikipedia AI Glossary](https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence)

_License: CC BY-SA 4.0_

_Source file: `data/terms/generative-ai.yml`_
