<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# gradient descent

**Aliases:** steepest descent, batch gradient descent
**Categories:** Foundations
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers
**Part of speech:** `process`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-09-29)

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Add this concept to onboarding materials so teammates share a common baseline.
- Link supporting research or documentation in your internal wiki for deeper study.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Iterative optimization algorithm that updates model parameters in the direction of the negative gradient to minimize a loss function.

## Long definition
Gradient descent is the workhorse optimization routine behind many machine learning models. The algorithm measures how the loss function changes with respect to each parameter, then nudges those parameters in the direction that most quickly reduces the loss. Step size is controlled by the learning rate, and the procedure repeats until convergence or an early stopping rule triggers. Product teams see the effects of gradient descent in training curves and quality improvements, engineers focus on stability and runtime characteristics, and data scientists tune batch size, momentum, and learning rate schedules to balance accuracy with compute budget. Understanding gradient descent is critical when diagnosing training instability, bias amplification, or regressions after feature changes because it exposes how the model is navigating its optimization landscape.

## Audience perspectives
- **Exec:** Gradient descent is the routine that steadily adjusts model knobs until errors shrink.
- **Engineer:** Compute parameter updates using grad_theta L(theta); tune learning rate, batching, and momentum to ensure stable convergence.

## Examples
**Do**
- Monitor training and validation loss together to catch divergence early.
- Scale learning rates with batch size when moving between GPU configurations.

**Don't**
- Ignore exploding gradients without adding clipping or schedule adjustments.
- Assume a single learning rate works across every feature or dataset refresh.

## Governance
- **NIST RMF tags:** validity, reliability
- **Risk notes:** Poorly tuned optimization can encode bias or destabilize production models, so training controls and reviews are essential.

## Relationships
- **Related:** loss function, regularization, fine-tuning

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'gradient descent'.

## Citations
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary)
- [DeepLearning.AI Resources](https://www.deeplearning.ai/resources/)
- [Hugging Face Course](https://huggingface.co/learn/deep-learning-course/unit5)

_License: CC BY-SA 4.0_

_Source file: `data/terms/gradient-descent.yml`_
