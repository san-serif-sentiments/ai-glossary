<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# algorithmic impact assessment

**Aliases:** AIA, AI impact assessment
**Categories:** Governance & Risk
**Roles:** Policy & Risk, Legal & Compliance, Product & Program Managers, Communications & Enablement, Engineering & Platform
**Part of speech:** `process`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-09-29)

## Role takeaways
- **Policy & Risk:** Map the definition to governance controls and review checklists.
- **Legal & Compliance:** Assess contractual and regulatory obligations tied to this term.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.
- **Communications & Enablement:** Align messaging, FAQs, and enablement materials using this definition.
- **Engineering & Platform:** Document implementation requirements and operational caveats.

## Practice & apply
- Map this term to the governance dashboard and record accountable owners in the backlog.
- Review current regulatory guidance or internal policy notes linked from the resources page before sign-off.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Structured review that documents how an AI system may affect people, processes, and compliance obligations.

## Long definition
Algorithmic impact assessments (AIAs) extend privacy and safety assessments to machine learning systems. They inventory intended uses, stakeholders, datasets, and model decisions; surface potential harms or rights impacts; and log mitigation plans before launch. Mature teams combine qualitative stakeholder interviews with quantitative evidence from evaluations, bias testing, and monitoring. The process forces clarity on accountability, human oversight, documentation, and escalation paths so downstream teams can manage risk. Governments increasingly mandate AIAs for high-risk use cases, making them a practical way to align product roadmaps with regulatory expectations. When revisited after major releases, AIAs become living records that connect model behavior to governance controls and public transparency.

## Audience perspectives
- **Exec:** An AIA proves we understand who an AI system could impact and how we will keep those risks managed.
- **Engineer:** Document data, model, and deployment assumptions so policy and legal partners can catch misaligned behavior before launch.

## Examples
**Do**
- Collect evaluation metrics, human feedback, and red-team findings as evidence in the AIA dossier.

**Don't**
- Treat the AIA as a one-time checklist that never gets updated after launch.

## Governance
- **NIST RMF tags:** accountability, risk_management, transparency
- **Risk notes:** Skipping AIAs leaves organizations unable to show regulators how risks were identified or mitigated.

## Relationships
- **Broader:** responsible ai, model governance
- **Related:** privacy impact assessment, red teaming, evaluation

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'algorithmic impact assessment'.

## Citations
- [OECD AI Glossary](https://oecd.ai/en/glossary)
- [AI Now Institute Lexicon](https://www.partnershiponai.org/glossary/)
- [Partnership on AI Glossary](https://www.partnershiponai.org/glossary/)

_License: CC BY-SA 4.0_

_Source file: `data/terms/algorithmic-impact-assessment.yml`_
