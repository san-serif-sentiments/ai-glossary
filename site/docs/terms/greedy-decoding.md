<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# greedy decoding

**Aliases:** argmax decoding
**Categories:** LLM Core
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers
**Part of speech:** `process`
**Status:** <span class="status-chip status-reviewed">Reviewed</span> (Last reviewed: 2025-09-28)

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Prototype behaviour changes in a sandbox notebook and capture prompt or decoding settings for others.
- Share findings with enablement so downstream teams understand model implications.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Strategy that selects the highest-probability token at each step, producing deterministic outputs.

## Long definition
Greedy decoding generates text by repeatedly choosing the token with the maximum probability, skipping any sampling. The approach is deterministic, fast, and easy to reason about, which makes it attractive for scenarios that demand consistency or auditability. However, it can lead to repetitive phrasing, premature endings, or failure to explore alternative but valid continuations. Product teams deploy greedy decoding for transactional tasks such as structured responses, deterministic workflows, or template filling, where creativity is less important than reliability. Engineers monitor for mode collapse and may add techniques like repetition penalties or suffix constraints to mitigate degenerate loops. Governance teams value greedy decoding because it simplifies compliance reviews and reproducibility: the same prompt always yields the same answer. Nonetheless, the lack of variation can hide blind spots if evaluations rely solely on argmax outputs, so organizations often complement greedy decoding tests with sampling-based stress cases.

## Audience perspectives
- **Exec:** Greedy decoding delivers the same answer every time, prioritizing consistency over creativity.
- **Engineer:** Iteratively pick the argmax token from the softmax distribution, allowing deterministic, low-latency generation.

## Examples
**Do**
- Use greedy decoding for policy disclosures where text must match approved language.

**Don't**
- Rely on greedy decoding alone when testing for harmful edge cases that require sampling diversity.

## Governance
- **NIST RMF tags:** validity, accountability
- **Risk notes:** Deterministic decoding simplifies audits but can mask untested behaviors that appear only with sampling.

## Relationships
- **Broader:** decoding
- **Related:** top-k sampling, top-p sampling, temperature

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'greedy decoding'.

## Citations
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary)
- [Hugging Face Glossary](https://huggingface.co/docs/transformers/en/glossary)
- [Wikipedia AI Glossary](https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence)

_License: CC BY-SA 4.0_

_Source file: `data/terms/greedy-decoding.yml`_
