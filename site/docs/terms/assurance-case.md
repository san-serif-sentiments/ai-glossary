<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# assurance case

**Aliases:** safety case, structured assurance argument
**Categories:** Governance & Risk
**Roles:** Policy & Risk, Legal & Compliance, Engineering & Platform
**Part of speech:** `noun_phrase`
**Status:** <span class="status-chip status-reviewed">Reviewed</span> (Last reviewed: 2025-09-28)

## Role takeaways
- **Policy & Risk:** Map the definition to governance controls and review checklists.
- **Legal & Compliance:** Assess contractual and regulatory obligations tied to this term.
- **Engineering & Platform:** Document implementation requirements and operational caveats.

## Practice & apply
- Map this term to the governance dashboard and record accountable owners in the backlog.
- Review current regulatory guidance or internal policy notes linked from the resources page before sign-off.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Structured argument that proves an AI system meets safety and compliance expectations.

## Long definition
An assurance case is a structured, evidence-backed argument that a system satisfies defined safety, ethics, and regulatory claims. Borrowed from aviation and medical devices, it organizes claims, supporting evidence, and reasoning into a traceable hierarchy so reviewers can judge whether an AI system is trustworthy. In practice, the case links risk registers, evaluation results, mitigations, and operating procedures to each claim. Policy and legal teams determine the claims needed for compliance, engineering curates the technical evidence, and product leaders maintain change logs so the case stays current across releases. Without a living assurance case, it is hard to demonstrate due diligence to regulators or to coordinate sign-off across governance bodies.

## Audience perspectives
- **Exec:** Use assurance cases to consolidate the evidence your board and regulators expect before high-risk launches.
- **Engineer:** Flow evaluation metrics, mitigations, and incident learnings into a single structured argument for review.

## Examples
**Do**
- Map every top risk in the register to a specific mitigation and evaluation artifact within the case.
- Schedule periodic refreshes so control owners update evidence before expiry.

**Don't**
- Rely on unstructured wikis or slides that obscure which claims the evidence supports.
- Freeze the case after initial approval, causing drift between documentation and production behavior.

## Governance
- **NIST RMF tags:** governance, accountability, risk_management
- **Risk notes:** Missing or outdated assurance arguments weaken regulatory defenses and slow executive approvals.

## Relationships
- **Broader:** ai assurance, model governance
- **Related:** risk register, impact mitigation plan, transparency report

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'assurance case'.

## Citations
- [OECD AI Glossary – Assurance Case](https://oecd.ai/en/glossary/details/assurance-case)
- [Partnership on AI – Safety Critical AI Assurance](https://partnershiponai.org/resource/safety-critical-ai-assurance/)

_License: CC BY-SA 4.0_

_Source file: `data/terms/assurance-case.yml`_
