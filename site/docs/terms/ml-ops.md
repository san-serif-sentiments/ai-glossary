<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# ml ops

**Aliases:** mlops, machine learning operations
**Categories:** Operations & Monitoring
**Roles:** Engineering & Platform, Policy & Risk, Security & Trust
**Part of speech:** `concept`
**Status:** `draft` (Last reviewed: 2024-11-01)

## Short definition
Operational discipline that manages ML models from experimentation through deployment and monitoring.

## Long definition
ML Ops adapts DevOps and data engineering practices to the lifecycle of machine learning systems. It encompasses experiment tracking, feature management, deployment automation, monitoring, incident response, and governance. Successful ML Ops programs unify teams across data science, engineering, and compliance so models move from prototype to production without manual heroics. Tooling includes model registries, CI/CD pipelines, automated evaluation gates, and observability platforms that watch for drift, data quality issues, and guardrail violations. Product organizations rely on ML Ops maturity to ship updates safely and respond quickly to incidents. Governance frameworks such as the NIST AI RMF expect documented ML Ops processes to demonstrate accountability, transparency, and continuous monitoring. Without disciplined ML Ops, models stagnate, degrade in accuracy, or fall out of compliance as the environment evolves.

## Audience perspectives
- **Exec:** ML Ops is the operating system that keeps production models reliable, compliant, and cost-efficient.
- **Engineer:** Integrate version control, CI/CD, registries, approvals, and monitoring to manage ML artifacts end to end.

## Examples
**Do**
- Automate promotion from staging to production only after evaluation and guardrail checks pass.

**Don't**
- Deploy model updates outside the pipeline, bypassing logging and rollback controls.

## Governance
- **NIST RMF tags:** accountability, monitoring
- **Risk notes:** Weak ML Ops processes increase the odds of untracked changes, bias reintroductions, and compliance failures.

## Relationships
- **Broader:** model governance
- **Narrower:** ml observability, model drift
- **Related:** fine-tuning, evaluation, guardrails

## Citations
- [NIST AI RMF Glossary](https://airc.nist.gov/glossary/)
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary)
- [Stanford HAI Brief Definitions](https://hai.stanford.edu/news/brief-definitions)

_License: CC BY-SA 4.0_

_Source file: `data/terms/ml-ops.yml`_
