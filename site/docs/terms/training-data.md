<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# training data

**Aliases:** training set, learning set
**Categories:** Foundations
**Roles:** Data Science & Research, Engineering & Platform, Product & Program Managers
**Part of speech:** `noun`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-09-29)

## Role takeaways
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Add this concept to onboarding materials so teammates share a common baseline.
- Link supporting research or documentation in your internal wiki for deeper study.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Labeled examples the model learns from before it ever sees validation or test inputs.

## Long definition
Training data is the portion of the dataset used to fit model parameters. These examples expose the algorithm to the signals it should internalize, from class boundaries to feature interactions. High-quality training data mirrors the production environment, includes the right balance of cohorts, and has documented provenance so teams can trace issues. Engineers tune hyperparameters and optimization steps against this split, while product partners track which customer or policy scenarios are represented. Weak training data leads to brittle models that memorize quirks rather than patterns, increasing the odds of bias, regressions, and governance failures when the system is deployed.

## Audience perspectives
- **Exec:** Training data is the fuel that teaches the model what "good" looks like before launch.
- **Engineer:** Curate representative, versioned examples with clear labels; document preprocessing and access controls.

## Examples
**Do**
- Record data lineage and consent before moving samples into the training set.
- Refresh training data when product usage, markets, or regulations shift.

**Don't**
- Mix evaluation samples back into training without resetting benchmark baselines.
- Ignore gaps in protected classes or edge scenarios that appear in production.

## Governance
- **NIST RMF tags:** data_quality, transparency
- **Risk notes:** Poorly governed training data creates hidden bias and auditing gaps that surface as fairness or compliance incidents.

## Relationships
- **Related:** data lineage, cross-validation, generalization, regularization

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'training data'.

## Citations
- [Google ML Glossary](https://developers.google.com/machine-learning/glossary#training-set)
- [NIST AI Risk Management Framework](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf)
- [Open Data Institute â€“ Data Assurance](https://theodi.org/article/data-assurance-guidance/)

_License: CC BY-SA 4.0_

_Source file: `data/terms/training-data.yml`_
