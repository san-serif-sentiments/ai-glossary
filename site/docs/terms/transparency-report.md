<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# transparency report

**Aliases:** algorithmic transparency report, safety disclosure report
**Categories:** Governance & Risk
**Roles:** Policy & Risk, Legal & Compliance, Communications & Enablement, Product & Program Managers
**Part of speech:** `noun_phrase`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-09-29)

## Role takeaways
- **Policy & Risk:** Map the definition to governance controls and review checklists.
- **Legal & Compliance:** Assess contractual and regulatory obligations tied to this term.
- **Communications & Enablement:** Align messaging, FAQs, and enablement materials using this definition.
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.

## Practice & apply
- Map this term to the governance dashboard and record accountable owners in the backlog.
- Review current regulatory guidance or internal policy notes linked from the resources page before sign-off.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Periodic disclosure that details how an AI system operates, what data it handles, and how risks are mitigated.

## Long definition
A transparency report is a structured publication that explains how an AI system was built, deployed, and governed. It typically documents training data provenance, safety mitigations, evaluation outcomes, incidents, and law-enforcement or policy interactions. Regulators increasingly require providers to publish these reports on a fixed cadence, while enterprises use them to demonstrate accountability to customers and civil society. Effective reports pair quantitative metrics with narrative context so stakeholders can understand both capabilities and limitations. Policy and legal teams coordinate the disclosure scope, communications tailors the narrative, and product owners provide operational detail. Without disciplined reporting, organizations struggle to prove compliance, respond to audits, or build trust with users.

## Audience perspectives
- **Exec:** Use transparency reports to show regulators and customers that your AI program meets accountability expectations.
- **Engineer:** Treat the report as a contract: ensure logs, metrics, and documentation can back every disclosure you publish.

## Examples
**Do**
- Publish red-team findings, mitigation steps, and open risks alongside capability highlights.
- Describe data retention periods and consent mechanisms in plain language instead of legal shorthand.

**Don't**
- Release marketing copy that omits failure modes, known biases, or the limits of human oversight.
- Bundle multiple system changes into one vague update that hides the timeline regulators expect.

## Governance
- **NIST RMF tags:** transparency, accountability, governance
- **Risk notes:** Incomplete or inaccurate disclosures expose the organization to regulatory penalties and reputational damage.

## Relationships
- **Broader:** responsible ai, model governance
- **Narrower:** safety spec, risk register
- **Related:** algorithmic audit, ai assurance, privacy impact assessment

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'transparency report'.

## Citations
- [European Commission – DSA Transparency Database](https://digital-strategy.ec.europa.eu/en/policies/dsa-transparency-database)
- [Partnership on AI – Transparency Reporting Template](https://partnershiponai.org/resource/transparency-reporting-template/)

_License: CC BY-SA 4.0_

_Source file: `data/terms/transparency-report.yml`_
