<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

# generalization

**Aliases:** generalisation, out-of-sample performance
**Categories:** Foundations
**Roles:** Product & Program Managers, Engineering & Platform, Data Science & Research
**Part of speech:** `noun`
**Status:** <span class="status-chip status-approved">Approved</span> (Last reviewed: 2025-09-29)

## Role takeaways
- **Product & Program Managers:** Translate this concept into user impact and rollout plans.
- **Engineering & Platform:** Document implementation requirements and operational caveats.
- **Data Science & Research:** Incorporate the metric or method into evaluation pipelines.

## Practice & apply
- Add this concept to onboarding materials so teammates share a common baseline.
- Link supporting research or documentation in your internal wiki for deeper study.
- Share takeaways with the accountable roles listed above so actions land with the right owners.

## Short definition
Model's ability to sustain performance on unseen data rather than memorising the training set.

## Long definition
Generalization determines whether a model delivers value once it leaves the lab. A system that overfits will look strong on training data but collapse when it meets new markets, languages, or customer behaviours. Engineering teams manage generalization by pairing representative train/validation/test splits with regularization, augmentation, and drift monitoring. Product and policy partners translate generalization risk into business and compliance exposure: degraded accuracy erodes customer trust, introduces bias, and can violate contractual or regulatory commitments. Healthy generalization comes from both technical controls and operational hygiene: clear loss functions, reproducible experiments, and post-deployment telemetry that surfaces when reality shifts away from the training distribution.

## Audience perspectives
- **Exec:** Generalization shows whether the model keeps its promises once it meets real customers and scenarios.
- **Engineer:** Track performance on held-out and in-production slices, tune regularization, and trigger retraining when drift appears.

## Examples
**Do**
- Hold back a realistic test set and monitor post-launch telemetry to confirm generalization.
- Log distribution shifts and retrain when key features move away from training baselines.

**Don't**
- Ship models based solely on training metrics or synthetic benchmarks.
- Ignore subgroup breakdowns that reveal poor generalization for protected or high-value cohorts.

## Governance
- **NIST RMF tags:** validity, robustness
- **Risk notes:** Poor generalization is a leading indicator of bias, drift, and safety incidents, so governance reviews demand evidence of monitoring.

## Relationships
- **Broader:** evaluation
- **Related:** bias-variance tradeoff, cross-validation, regularization, model drift

!!! info "Something missing?"
    Suggest examples or clarifications via the [term request intake](../term-request.md) and mention 'generalization'.

## Citations
- [Deep Learning (MIT Press)](https://www.deeplearningbook.org/)
- [NIST AI Risk Management Framework](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf)
- [Hugging Face Glossary](https://huggingface.co/docs/transformers/en/glossary)

_License: CC BY-SA 4.0_

_Source file: `data/terms/generalization.yml`_
