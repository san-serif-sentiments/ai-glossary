term: "self-consistency decoding"
aliases:
  - "self-consistency"
  - "majority-vote reasoning"
categories:
  - "LLM Core"
roles:
  - "engineering"
  - "data_science"
part_of_speech: "process"
short_def: "Decoding strategy that samples multiple reasoning paths and aggregates the most consistent answer."
long_def: >-
  Self-consistency decoding runs a model several times with chain-of-thought prompts, then selects the answer that appears
  most frequently across the sampled reasoning paths. The approach boosts accuracy on reasoning tasks by reducing the
  impact of any single hallucinated chain. Engineers trade off latency and cost for higher reliability, while data
  scientists evaluate how many samples are needed to meaningfully improve accuracy. The technique pairs well with
  automated checkers that verify the final answer. Without careful tuning, self-consistency can reinforce common but
  incorrect answers or leak sensitive reasoning traces.
audiences:
  exec: "Use self-consistency when critical decisions require higher reasoning confidence."
  engineer: "Balance sampling counts with latency budgets and audit reasoning traces for policy compliance."
examples:
  do:
    - "Combine self-consistency with validators that check math or policy compliance."
    - "Log sampled chains for debugging and evaluation."
  dont:
    - "Assume majority vote guarantees correctness without external checks."
    - "Leak sensitive instruction text in stored reasoning chains."
governance:
  nist_rmf_tags:
    - "monitoring"
    - "risk_management"
  risk_notes: "Sampling multiple chains increases cost and potential exposure of sensitive intermediate reasoning."
relationships:
  broader:
    - "decoding"
  related:
    - "chain-of-thought prompting"
    - "robust prompting"
    - "evaluation harness"
citations:
  - source: "Google – Self-Consistency Improves Chain of Thought"
    url: "https://arxiv.org/abs/2203.11171"
  - source: "OpenAI – Better Language Models and Their Implications"
    url: "https://openai.com/research/better-language-models"
license: "CC BY-SA 4.0"
status: "approved"
last_reviewed: "2025-09-29"
