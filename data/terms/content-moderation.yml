term: "content moderation"
aliases:
  - "trust and safety"
  - "policy enforcement"
categories:
  - "Governance & Risk"
  - "Operations & Monitoring"
roles:
  - "policy"
  - "communications"
  - "product"
  - "security"
  - "engineering"
part_of_speech: "process"
short_def: "Workflows and tools that review, filter, and act on user-generated content to enforce policy."
long_def: >-
  Content moderation combines automation, human review, and escalation procedures to detect policy violations such as hate speech, harassment, misinformation, or disallowed imagery. AI systems often provide the first layer of moderation by classifying or scoring content for human queues, requiring careful tuning of precision/recall trade-offs. Policy teams define enforcement rules, while communications and legal stakeholders handle appeals and transparency reports. Engineering teams maintain moderation pipelines, logging, and guardrails; security teams ensure abuse detection remains resilient. Effective moderation programs rely on measurement, red-teaming, and incident response to adapt to adversarial users and evolving regulations.
audiences:
  exec: "Content moderation protects users and the brand by keeping AI outputs and user posts within policy."
  engineer: "Blend classifiers, heuristic filters, and human review; monitor performance, appeals, and adversarial attempts." 
examples:
  do:
    - "Audit moderation models for bias against protected groups."
    - "Publish user-facing guidelines and escalation paths."
  dont:
    - "Rely solely on automation without human oversight for edge cases."
    - "Ignore feedback loops when policies change."
governance:
  nist_rmf_tags:
    - "risk_management"
    - "accountability"
  risk_notes: "Weak moderation exposes users to harm, invites regulatory fines, and erodes trust."
relationships:
  broader:
    - "guardrails"
  related:
    - "safety evaluation"
    - "incident response"
    - "algorithmic bias"
citations:
  - source: "European Commission â€“ Content Moderation Policy"
    url: "https://digital-strategy.ec.europa.eu/en/policies/content-moderation"
  - source: "NIST AI RMF Glossary"
    url: "https://www.nist.gov/itl/ai-risk-management-framework"
  - source: "Stanford HAI Brief Definitions"
    url: "https://hai.stanford.edu/news/brief-definitions"
license: "CC BY-SA 4.0"
status: "approved"
last_reviewed: "2025-09-29"
