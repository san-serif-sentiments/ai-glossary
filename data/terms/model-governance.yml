term: "model governance"
aliases:
  - "ai governance"
  - "ml governance"
categories:
  - "Governance & Risk"
roles:
  - "communications"
  - "legal"
  - "policy"
  - "product"
part_of_speech: "concept"
short_def: "Policies and processes that manage AI models across risk, compliance, and lifecycle decisions."
long_def: >-
  Model governance coordinates legal, risk, engineering, and product roles to oversee how AI systems are developed, deployed, and maintained. Core activities include documenting intended use, validating data sources, approving releases, monitoring for drift, and managing incidents. Governance frameworks—such as the NIST AI RMF or ISO/IEC standards—expect organizations to maintain traceability for models, prompts, datasets, and evaluation evidence. Committees or designated owners review changes, enforce segregation of duties, and ensure audits can reconstruct decisions. Product teams rely on governance guardrails to align with policy, while engineers integrate governance checkpoints into ML Ops pipelines. Without governance, AI initiatives accumulate technical debt, expose companies to regulatory penalties, and erode user trust. Mature governance balances innovation with accountability, enabling responsible scaling of AI capabilities.
audiences:
  exec: "Model governance keeps AI programs aligned with policy, compliance, and stakeholder expectations as they scale."
  engineer: "Define ownership, documentation, approvals, and monitoring requirements so every model change is auditable."
examples:
  do:
    - "Record decision logs and reviewers for each production model release."
  dont:
    - "Deploy models without documenting purpose, controls, and evaluation results."
governance:
  nist_rmf_tags:
    - "accountability"
    - "risk_management"
  risk_notes: "Absent governance leads to untracked risks, inconsistent controls, and regulatory exposure."
relationships:
  broader:
    - "responsible ai"
  narrower:
    - "ml ops"
    - "model drift"
    - "ai incident response"
  related:
    - "evaluation"
    - "alignment"
    - "guardrails"
citations:
  - source: "NIST AI Risk Management Framework"
    url: "https://www.nist.gov/itl/ai-risk-management-framework"
  - source: "IBM – What Is AI Governance?"
    url: "https://www.ibm.com/topics/ai-governance"
  - source: "White House Executive Order 14110 on Safe, Secure, and Trustworthy AI"
    url: "https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/"
license: "CC BY-SA 4.0"
status: "approved"
last_reviewed: "2025-09-29"
