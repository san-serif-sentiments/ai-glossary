term: "assurance case"
aliases:
  - "safety case"
  - "structured assurance argument"
categories:
  - "Governance & Risk"
roles:
  - "policy"
  - "legal"
  - "engineering"
part_of_speech: "noun_phrase"
short_def: "Structured argument that proves an AI system meets safety and compliance expectations."
long_def: >-
  An assurance case is a structured, evidence-backed argument that a system satisfies defined safety, ethics, and
  regulatory claims. Borrowed from aviation and medical devices, it organizes claims, supporting evidence, and
  reasoning into a traceable hierarchy so reviewers can judge whether an AI system is trustworthy. In practice, the
  case links risk registers, evaluation results, mitigations, and operating procedures to each claim. Policy and
  legal teams determine the claims needed for compliance, engineering curates the technical evidence, and product
  leaders maintain change logs so the case stays current across releases. Without a living assurance case, it is hard
  to demonstrate due diligence to regulators or to coordinate sign-off across governance bodies.
audiences:
  exec: "Use assurance cases to consolidate the evidence your board and regulators expect before high-risk launches."
  engineer: "Flow evaluation metrics, mitigations, and incident learnings into a single structured argument for review."
examples:
  do:
    - "Map every top risk in the register to a specific mitigation and evaluation artifact within the case."
    - "Schedule periodic refreshes so control owners update evidence before expiry."
  dont:
    - "Rely on unstructured wikis or slides that obscure which claims the evidence supports."
    - "Freeze the case after initial approval, causing drift between documentation and production behavior."
governance:
  nist_rmf_tags:
    - "governance"
    - "accountability"
    - "risk_management"
  risk_notes: "Missing or outdated assurance arguments weaken regulatory defenses and slow executive approvals."
relationships:
  broader:
    - "ai assurance"
    - "model governance"
  related:
    - "risk register"
    - "impact mitigation plan"
    - "transparency report"
citations:
  - source: "OECD AI Glossary – Assurance Case"
    url: "https://oecd.ai/en/glossary/details/assurance-case"
  - source: "Partnership on AI – Safety Critical AI Assurance"
    url: "https://www.partnershiponai.org/resource/a-safety-critical-ai-assurance-framework/"
license: "CC BY-SA 4.0"
status: "approved"
last_reviewed: "2025-09-29"
