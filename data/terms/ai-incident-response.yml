term: "ai incident response"
aliases:
  - "model incident response"
  - "ai escalation"
categories:
  - "Operations & Monitoring"
  - "Governance & Risk"
roles:
  - "communications"
  - "engineering"
  - "legal"
  - "policy"
  - "product"
  - "security"
part_of_speech: "process"
short_def: "Coordinated workflow for detecting, triaging, and remediating harmful or out-of-policy AI behavior."
long_def: >-
  AI incident response adapts traditional incident management to the unique risks of machine learning systems. It defines how teams detect unusual behavior, declare incidents, assemble cross-functional responders, communicate with stakeholders, and deploy mitigations or rollbacks. Triggers include safety violations, hallucinations with material impact, security breaches, or regulatory inquiries. Effective programs maintain runbooks that cover data isolation, prompt freezes, feature flags, and guardrail adjustments. Product, engineering, legal, and communications partners collaborate to assess severity, user impact, and reporting obligations. Governance frameworks expect documented incident response procedures with clear owners and timelines, particularly for high-risk deployments. After-action reviews capture learnings that feed back into evaluation suites, prompts, and monitoring. Without a disciplined incident response plan, organizations risk delayed containment, regulatory penalties, and erosion of user trust.
audiences:
  exec: "AI incident response is the playbook that keeps harm contained and stakeholders informed when something goes wrong."
  engineer: "Detect anomalies, page the on-call rotation, freeze risky components, and coordinate fixes across data, model, and infra teams."
examples:
  do:
    - "Run quarterly tabletop exercises to rehearse AI incident response workflows."
  dont:
    - "Silence alerts or skip postmortems once an incident is closed."
governance:
  nist_rmf_tags:
    - "risk_management"
    - "accountability"
  risk_notes: "Lack of documented response plans prolongs harmful behavior and undermines regulatory reporting."
relationships:
  broader:
    - "model governance"
  related:
    - "red teaming"
    - "guardrails"
    - "ml observability"
citations:
  - source: "NIST AI Risk Management Framework"
    url: "https://www.nist.gov/itl/ai-risk-management-framework"
  - source: "CISA – AI Security Incident Response Guidelines"
    url: "https://www.cisa.gov/resources-tools/resources/artificial-intelligence-security-incident-response-guidelines"
  - source: "Center for Internet Security – Developing an AI Incident Response Plan"
    url: "https://www.cisecurity.org/insights/blog"
license: "CC BY-SA 4.0"
status: "approved"
last_reviewed: "2025-09-29"
