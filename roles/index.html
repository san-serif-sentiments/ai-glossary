
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A cross-functional, citation-backed vocabulary for AI teams.">
      
      
      
        <link rel="canonical" href="https://san-serif-sentiments.github.io/ai-glossary/roles/">
      
      
        <link rel="prev" href="../search/">
      
      
        <link rel="next" href="../categories/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.15">
    
    
      
        <title>Role Starter Packs - AI Glossary</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e359304.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../styles.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="deep-orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#role-starter-packs" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="AI Glossary" class="md-header__button md-logo" aria-label="AI Glossary" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 2a2 2 0 0 1 2 2v16a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h12m0 2h-5v8l-2.5-2.25L8 12V4H6v16h12V4Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI Glossary
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Role Starter Packs
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="deep-orange"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/san-serif-sentiments/ai-glossary" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    san-serif-sentiments/ai-glossary
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="AI Glossary" class="md-nav__button md-logo" aria-label="AI Glossary" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 2a2 2 0 0 1 2 2v16a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h12m0 2h-5v8l-2.5-2.25L8 12V4H6v16h12V4Z"/></svg>

    </a>
    AI Glossary
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/san-serif-sentiments/ai-glossary" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    san-serif-sentiments/ai-glossary
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../resources/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Resources
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Glossary Terms
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Glossary Terms
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Role Starter Packs
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Role Starter Packs
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#product-program-managers" class="md-nav__link">
    <span class="md-ellipsis">
      Product &amp; Program Managers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Product & Program Managers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#guided-learning-path" class="md-nav__link">
    <span class="md-ellipsis">
      Guided learning path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practice-checklist" class="md-nav__link">
    <span class="md-ellipsis">
      Practice checklist
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#focus-areas" class="md-nav__link">
    <span class="md-ellipsis">
      Focus areas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recommended-terms" class="md-nav__link">
    <span class="md-ellipsis">
      Recommended terms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#engineering-platform" class="md-nav__link">
    <span class="md-ellipsis">
      Engineering &amp; Platform
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Engineering & Platform">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#guided-learning-path_1" class="md-nav__link">
    <span class="md-ellipsis">
      Guided learning path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practice-checklist_1" class="md-nav__link">
    <span class="md-ellipsis">
      Practice checklist
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#focus-areas_1" class="md-nav__link">
    <span class="md-ellipsis">
      Focus areas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recommended-terms_1" class="md-nav__link">
    <span class="md-ellipsis">
      Recommended terms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-science-research" class="md-nav__link">
    <span class="md-ellipsis">
      Data Science &amp; Research
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Science & Research">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#guided-learning-path_2" class="md-nav__link">
    <span class="md-ellipsis">
      Guided learning path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practice-checklist_2" class="md-nav__link">
    <span class="md-ellipsis">
      Practice checklist
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#focus-areas_2" class="md-nav__link">
    <span class="md-ellipsis">
      Focus areas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recommended-terms_2" class="md-nav__link">
    <span class="md-ellipsis">
      Recommended terms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#policy-risk" class="md-nav__link">
    <span class="md-ellipsis">
      Policy &amp; Risk
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Policy & Risk">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#guided-learning-path_3" class="md-nav__link">
    <span class="md-ellipsis">
      Guided learning path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practice-checklist_3" class="md-nav__link">
    <span class="md-ellipsis">
      Practice checklist
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#focus-areas_3" class="md-nav__link">
    <span class="md-ellipsis">
      Focus areas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recommended-terms_3" class="md-nav__link">
    <span class="md-ellipsis">
      Recommended terms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#legal-compliance" class="md-nav__link">
    <span class="md-ellipsis">
      Legal &amp; Compliance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Legal & Compliance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#guided-learning-path_4" class="md-nav__link">
    <span class="md-ellipsis">
      Guided learning path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practice-checklist_4" class="md-nav__link">
    <span class="md-ellipsis">
      Practice checklist
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#focus-areas_4" class="md-nav__link">
    <span class="md-ellipsis">
      Focus areas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recommended-terms_4" class="md-nav__link">
    <span class="md-ellipsis">
      Recommended terms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#security-trust" class="md-nav__link">
    <span class="md-ellipsis">
      Security &amp; Trust
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Security & Trust">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#guided-learning-path_5" class="md-nav__link">
    <span class="md-ellipsis">
      Guided learning path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practice-checklist_5" class="md-nav__link">
    <span class="md-ellipsis">
      Practice checklist
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#focus-areas_5" class="md-nav__link">
    <span class="md-ellipsis">
      Focus areas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recommended-terms_5" class="md-nav__link">
    <span class="md-ellipsis">
      Recommended terms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#communications-enablement" class="md-nav__link">
    <span class="md-ellipsis">
      Communications &amp; Enablement
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Communications & Enablement">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#guided-learning-path_6" class="md-nav__link">
    <span class="md-ellipsis">
      Guided learning path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practice-checklist_6" class="md-nav__link">
    <span class="md-ellipsis">
      Practice checklist
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#focus-areas_6" class="md-nav__link">
    <span class="md-ellipsis">
      Focus areas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recommended-terms_6" class="md-nav__link">
    <span class="md-ellipsis">
      Recommended terms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../categories/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Category Explorer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../prompting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Prompt Engineering Playbook
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../governance-dashboard/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Governance Dashboard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7" >
        
          
          <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Foundations
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7">
            <span class="md-nav__icon md-icon"></span>
            Foundations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/bias-variance-tradeoff/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bias-variance tradeoff
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    clip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/confusion-matrix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    confusion matrix
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/cross-validation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cross-validation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/diffusion-model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    diffusion model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/f1-score/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    f1 score
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/feature-engineering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feature engineering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/generalization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    generalization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/generative-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    generative ai
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/gradient-descent/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gradient descent
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/loss-function/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    loss function
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/overfitting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    overfitting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/precision/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    precision
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/recall/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    recall
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/regularization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    regularization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/roc-auc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    roc auc
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/target-variable/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    target variable
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/test-set/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test set
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/training-data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    training data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/validation-set/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    validation set
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/voice-cloning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    voice cloning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_8" >
        
          
          <label class="md-nav__link" for="__nav_3_8" id="__nav_3_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    LLM Core
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_8">
            <span class="md-nav__icon md-icon"></span>
            LLM Core
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/beam-search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/chain-of-thought-prompting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chain-of-thought prompting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/context-window/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    context window
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    decoding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/direct-preference-optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    direct preference optimization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/greedy-decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    greedy decoding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/hallucination/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hallucination
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/kv-cache/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    kv cache
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/log-probability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    log probability
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/preference-dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    preference dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/prompt-engineering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    prompt engineering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/reinforcement-learning-from-human-feedback/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    reinforcement learning from human feedback
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/repetition-penalty/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    repetition penalty
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/reward-model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    reward model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/robust-prompting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    robust prompting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/self-consistency-decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    self-consistency decoding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/system-prompt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    system prompt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/temperature/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    temperature
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/token/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    token
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/top-k-sampling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    top-k sampling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/top-p-sampling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    top-p sampling
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_9" >
        
          
          <label class="md-nav__link" for="__nav_3_9" id="__nav_3_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Retrieval & RAG
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_9">
            <span class="md-nav__icon md-icon"></span>
            Retrieval & RAG
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/chunking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chunking
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/embedding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    embedding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/reranking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    reranking
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/retrieval/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    retrieval
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/retrieval-augmented-generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    retrieval-augmented generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/vector-store/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vector store
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_10" >
        
          
          <label class="md-nav__link" for="__nav_3_10" id="__nav_3_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Agents & Tooling
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_10">
            <span class="md-nav__icon md-icon"></span>
            Agents & Tooling
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/agent-executor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    agent executor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/agentic-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    agentic ai
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/function-calling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    function calling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/human-handoff/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    human handoff
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/memory-strategy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    memory strategy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/self-critique-loop/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    self-critique loop
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/tool-use/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tool use
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_11" >
        
          
          <label class="md-nav__link" for="__nav_3_11" id="__nav_3_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Optimization & Efficiency
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_11">
            <span class="md-nav__icon md-icon"></span>
            Optimization & Efficiency
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/fine-tuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fine-tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/instruction-tuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    instruction tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/knowledge-distillation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    knowledge distillation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/low-rank-adaptation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    low-rank adaptation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/mixture-of-experts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mixture of experts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    quantization
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_12" >
        
          
          <label class="md-nav__link" for="__nav_3_12" id="__nav_3_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Operations & Monitoring
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_12">
            <span class="md-nav__icon md-icon"></span>
            Operations & Monitoring
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/ai-circuit-breaker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ai circuit breaker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/ai-incident-response/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ai incident response
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/data-lineage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data lineage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/evaluation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    evaluation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/evaluation-harness/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    evaluation harness
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/incident-taxonomy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    incident taxonomy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/ml-observability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ml observability
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/ml-ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ml ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/model-drift/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    model drift
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/shadow-deployment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    shadow deployment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/synthetic-data-evaluation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    synthetic data evaluation
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_13" >
        
          
          <label class="md-nav__link" for="__nav_3_13" id="__nav_3_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Governance & Risk
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_13">
            <span class="md-nav__icon md-icon"></span>
            Governance & Risk
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/ai-assurance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ai assurance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/algorithmic-audit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    algorithmic audit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/algorithmic-bias/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    algorithmic bias
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/algorithmic-impact-assessment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    algorithmic impact assessment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/alignment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    alignment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/assurance-case/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    assurance case
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/consent-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    consent management
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/constitutional-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    constitutional ai
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/content-moderation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    content moderation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/data-minimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data minimization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/data-redaction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data redaction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/data-retention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data retention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/dataset-card/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    dataset card
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/differential-privacy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    differential privacy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/escalation-policy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    escalation policy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/fairness-metrics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fairness metrics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/guardrail-policy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    guardrail policy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/guardrails/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    guardrails
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/impact-mitigation-plan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    impact mitigation plan
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/jailbreak-prompt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    jailbreak prompt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/model-card/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    model card
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/model-governance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    model governance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/model-interpretability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    model interpretability
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/privacy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    privacy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/privacy-budget/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    privacy budget
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/privacy-impact-assessment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    privacy impact assessment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/prompt-injection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    prompt injection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/red-teaming/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    red teaming
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/responsible-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    responsible ai
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/risk-register/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    risk register
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/safety-classifier/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    safety classifier
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/safety-evaluation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    safety evaluation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/safety-review-board/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    safety review board
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/safety-spec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    safety spec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/synthetic-data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    synthetic data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terms/transparency-report/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    transparency report
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../data-model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Model
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Contributing
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Contributing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../contributing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Guide
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../keyword-backlog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Keyword Backlog
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../term-request/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Term Request Intake
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/san-serif-sentiments/ai-glossary/edit/master/docs/roles.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  


<!--
  This file is auto-generated by scripts/render_docs.py. Do not edit manually.
-->

<h1 id="role-starter-packs">Role Starter Packs<a class="headerlink" href="#role-starter-packs" title="Permanent link">&para;</a></h1>
<p>Guidance for common stakeholder groups. Each pack includes actionable steps and key focus areas so teams can operationalize insights immediately.</p>
<h2 id="product-program-managers">Product &amp; Program Managers<a class="headerlink" href="#product-program-managers" title="Permanent link">&para;</a></h2>
<p>Focus on user outcomes, feature scope, and launch readiness.</p>
<p><strong>Action plan</strong>
- Bookmark the <a href="../search/">Glossary Search</a> filtered to this role and review the top 5 unfamiliar terms.
- Schedule a sync with partner roles listed under each term to clarify ownership and open questions.
- Capture insights in your runbook or onboarding guide so future teammates ramp faster.</p>
<h3 id="guided-learning-path">Guided learning path<a class="headerlink" href="#guided-learning-path" title="Permanent link">&para;</a></h3>
<ol>
<li>Skim the Governance &amp; Risk category to learn which terms drive launch checklists.</li>
<li>Bookmark three model or prompt concepts that influence roadmap trade-offs.</li>
<li>Schedule a debrief with policy partners to align on escalation triggers.</li>
</ol>
<h3 id="practice-checklist">Practice checklist<a class="headerlink" href="#practice-checklist" title="Permanent link">&para;</a></h3>
<ul>
<li>Review the glossary search filtered to product + governance and log two takeaways in your launch checklist.</li>
<li>Pair with engineering to confirm which guardrails or prompts need updates before feature freeze.</li>
</ul>
<h3 id="focus-areas">Focus areas<a class="headerlink" href="#focus-areas" title="Permanent link">&para;</a></h3>
<ul>
<li>Governance &amp; Risk (38 terms)</li>
<li>LLM Core (24 terms)</li>
<li>Foundations (20 terms)</li>
<li>Operations &amp; Monitoring (15 terms)</li>
<li>Agents &amp; Tooling (7 terms)</li>
<li>Retrieval &amp; RAG (7 terms)</li>
<li>Optimization &amp; Efficiency (2 terms)</li>
</ul>
<h3 id="recommended-terms">Recommended terms<a class="headerlink" href="#recommended-terms" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="../terms/agent-executor/">agent executor</a> — Controller layer that schedules planning, tool calls, and stop conditions so an AI agent completes tasks safely.</li>
<li><a href="../terms/agentic-ai/">agentic ai</a> — Systems that plan, act, and iterate with minimal human prompts by chaining model calls and tools.</li>
<li><a href="../terms/ai-assurance/">ai assurance</a> — Discipline that produces evidence, controls, and attestations showing an AI system meets agreed safety, compliance, and performance thresholds.</li>
<li><a href="../terms/ai-circuit-breaker/">ai circuit breaker</a> — Automated control that halts model responses or tool access when risk thresholds are exceeded.</li>
<li><a href="../terms/ai-incident-response/">ai incident response</a> — Coordinated workflow for detecting, triaging, and remediating harmful or out-of-policy AI behavior.</li>
<li><a href="../terms/algorithmic-audit/">algorithmic audit</a> — Independent review of an AI system’s data, design, and outcomes to verify compliance, fairness, and risk controls.</li>
<li><a href="../terms/algorithmic-bias/">algorithmic bias</a> — Systematic unfairness in model outputs that disadvantages certain groups or outcomes.</li>
<li><a href="../terms/algorithmic-impact-assessment/">algorithmic impact assessment</a> — Structured review that documents how an AI system may affect people, processes, and compliance obligations.</li>
<li><a href="../terms/alignment/">alignment</a> — Making sure AI systems optimize for human values, policies, and intended outcomes.</li>
<li><a href="../terms/attention/">attention</a> — Technique enabling models to weight input tokens differently when producing each output.</li>
<li><a href="../terms/beam-search/">beam search</a> — Deterministic decoding that keeps the top scoring sequences across multiple beams before selecting the final output.</li>
<li><a href="../terms/chain-of-thought-prompting/">chain-of-thought prompting</a> — Prompting technique that asks models to reason through intermediate steps before giving a final answer.</li>
<li><a href="../terms/chunking/">chunking</a> — Splitting source documents into manageable pieces before indexing or feeding them to models.</li>
<li><a href="../terms/clip/">clip</a> — Multimodal model that embeds images and text into a shared space using contrastive learning.</li>
<li><a href="../terms/confusion-matrix/">confusion matrix</a> — Table that summarizes true/false positives and negatives to diagnose classification performance.</li>
<li><a href="../terms/consent-management/">consent management</a> — Practices that capture, honor, and audit user permissions across AI features.</li>
<li><a href="../terms/constitutional-ai/">constitutional ai</a> — Alignment approach where models critique and revise their own outputs against a written set of principles.</li>
<li><a href="../terms/content-moderation/">content moderation</a> — Workflows and tools that review, filter, and act on user-generated content to enforce policy.</li>
<li><a href="../terms/context-window/">context window</a> — Maximum number of tokens a model can consider at once during prompting or inference.</li>
<li><a href="../terms/cross-validation/">cross-validation</a> — Evaluation technique that splits data into multiple folds to estimate model performance on unseen samples.</li>
<li><a href="../terms/data-minimization/">data minimization</a> — Principle of collecting and retaining only the data necessary for a defined purpose.</li>
<li><a href="../terms/data-retention/">data retention</a> — Policies defining how long data is stored, where it lives, and how it is deleted.</li>
<li><a href="../terms/dataset-card/">dataset card</a> — Structured documentation describing a dataset’s purpose, composition, risks, and usage constraints.</li>
<li><a href="../terms/decoding/">decoding</a> — Algorithms that turn model probability distributions into output tokens during generation.</li>
<li><a href="../terms/diffusion-model/">diffusion model</a> — Generative model that iteratively denoises random noise to synthesize images, audio, or other data.</li>
<li><a href="../terms/direct-preference-optimization/">direct preference optimization</a> — Alignment technique that fine-tunes models directly on preference data without training a separate reward model.</li>
<li><a href="../terms/embedding/">embedding</a> — Dense numerical representation that captures semantic meaning of text, images, or other data.</li>
<li><a href="../terms/escalation-policy/">escalation policy</a> — Playbook that defines when and how AI systems route control to human reviewers.</li>
<li><a href="../terms/evaluation/">evaluation</a> — Systematic measurement of model performance, safety, and reliability using defined tests.</li>
<li><a href="../terms/evaluation-harness/">evaluation harness</a> — Automated pipeline that replays tasks, scores outputs, and reports regressions for AI systems.</li>
<li><a href="../terms/f1-score/">f1 score</a> — Harmonic mean of precision and recall, balancing false positives and false negatives.</li>
<li><a href="../terms/fairness-metrics/">fairness metrics</a> — Quantitative measures that evaluate whether model performance is equitable across groups.</li>
<li><a href="../terms/feature-engineering/">feature engineering</a> — Transforming raw data into model-ready features that improve signal, fairness, and maintainability.</li>
<li><a href="../terms/function-calling/">function calling</a> — LLM capability that lets prompts invoke predefined functions and return structured arguments.</li>
<li><a href="../terms/generalization/">generalization</a> — Model's ability to sustain performance on unseen data rather than memorising the training set.</li>
<li><a href="../terms/generative-ai/">generative ai</a> — Family of models that produce new content—text, images, code—rather than only making predictions.</li>
<li><a href="../terms/gradient-descent/">gradient descent</a> — Iterative optimization algorithm that updates model parameters in the direction of the negative gradient to minimize a loss function.</li>
<li><a href="../terms/greedy-decoding/">greedy decoding</a> — Strategy that selects the highest-probability token at each step, producing deterministic outputs.</li>
<li><a href="../terms/guardrail-policy/">guardrail policy</a> — Documented rules and prompts that define allowed, blocked, and escalated behaviors for AI systems.</li>
<li><a href="../terms/guardrails/">guardrails</a> — Controls that constrain model behavior to comply with safety, legal, or brand requirements.</li>
<li><a href="../terms/hallucination/">hallucination</a> — When an AI model presents fabricated or unsupported information as fact.</li>
<li><a href="../terms/human-handoff/">human handoff</a> — Moment when an AI workflow transfers control to a human for review or action.</li>
<li><a href="../terms/impact-mitigation-plan/">impact mitigation plan</a> — Action plan that tracks risks, mitigations, owners, and timelines for an AI deployment.</li>
<li><a href="../terms/incident-taxonomy/">incident taxonomy</a> — Standardized categories used to tag, analyze, and report AI incidents consistently.</li>
<li><a href="../terms/instruction-tuning/">instruction tuning</a> — Supervised training that teaches models to follow natural-language instructions using curated examples.</li>
<li><a href="../terms/jailbreak-prompt/">jailbreak prompt</a> — Crafted input that persuades a model to ignore safety instructions and produce disallowed responses.</li>
<li><a href="../terms/kv-cache/">kv cache</a> — Stored attention keys and values reused across decoding steps to speed sequential generation.</li>
<li><a href="../terms/log-probability/">log probability</a> — Logarithm of a token’s probability, used to inspect model confidence and guide decoding tweaks.</li>
<li><a href="../terms/loss-function/">loss function</a> — Mathematical rule that scores how far model predictions deviate from desired targets.</li>
<li><a href="../terms/memory-strategy/">memory strategy</a> — Deliberate approach for when an AI agent stores, retrieves, or forgets context across tasks.</li>
<li><a href="../terms/mixture-of-experts/">mixture of experts</a> — Neural architecture that routes tokens to specialized submodels to scale capacity efficiently.</li>
<li><a href="../terms/model-card/">model card</a> — Standardized documentation describing a model’s purpose, data, performance, and limitations.</li>
<li><a href="../terms/model-drift/">model drift</a> — Gradual mismatch between model assumptions and real-world data that degrades performance over time.</li>
<li><a href="../terms/model-governance/">model governance</a> — Policies and processes that manage AI models across risk, compliance, and lifecycle decisions.</li>
<li><a href="../terms/model-interpretability/">model interpretability</a> — Ability to explain how a model arrives at its predictions in ways stakeholders understand.</li>
<li><a href="../terms/overfitting/">overfitting</a> — When a model memorizes training data patterns so closely that it performs poorly on new samples.</li>
<li><a href="../terms/precision/">precision</a> — Share of predicted positives that are actually correct for a given classifier.</li>
<li><a href="../terms/preference-dataset/">preference dataset</a> — Labeled comparisons of model outputs that capture which responses humans prefer.</li>
<li><a href="../terms/privacy/">privacy</a> — Principle of limiting data collection, use, and exposure to protect individuals’ information.</li>
<li><a href="../terms/privacy-impact-assessment/">privacy impact assessment</a> — Structured review that evaluates how a system collects, uses, and safeguards personal data.</li>
<li><a href="../terms/prompt-engineering/">prompt engineering</a> — Crafting and testing prompts to steer model behavior toward desired outcomes.</li>
<li><a href="../terms/prompt-injection/">prompt injection</a> — Attack that inserts malicious instructions into model inputs to override original prompts or policies.</li>
<li><a href="../terms/recall/">recall</a> — Share of actual positives a model successfully identifies.</li>
<li><a href="../terms/red-teaming/">red teaming</a> — Deliberate stress testing that probes AI systems for harmful, biased, or policy-violating behavior.</li>
<li><a href="../terms/regularization/">regularization</a> — Techniques that add penalties or constraints during training to reduce overfitting and improve generalisation.</li>
<li><a href="../terms/reinforcement-learning-from-human-feedback/">reinforcement learning from human feedback</a> — Training approach that tunes a model using reward signals learned from human preference data.</li>
<li><a href="../terms/repetition-penalty/">repetition penalty</a> — Decoding adjustment that down-weights tokens already generated to reduce loops and repeated phrases.</li>
<li><a href="../terms/reranking/">reranking</a> — Step that refines retrieval results using a more precise but slower scoring model.</li>
<li><a href="../terms/responsible-ai/">responsible ai</a> — Frameworks and practices that ensure AI systems are safe, fair, and aligned with ethical and legal expectations.</li>
<li><a href="../terms/retrieval/">retrieval</a> — Process of selecting relevant documents or vectors from a corpus in response to a query.</li>
<li><a href="../terms/retrieval-augmented-generation/">retrieval-augmented generation</a> — Workflow that grounds a generative model with retrieved context before producing output.</li>
<li><a href="../terms/risk-register/">risk register</a> — Central list of identified AI risks, their owners, mitigations, and review status.</li>
<li><a href="../terms/robust-prompting/">robust prompting</a> — Prompt design techniques that harden models against injections, ambiguity, and unsafe outputs.</li>
<li><a href="../terms/roc-auc/">roc auc</a> — Metric summarizing binary classifier performance by measuring area under the ROC curve.</li>
<li><a href="../terms/safety-classifier/">safety classifier</a> — Model that detects policy-violating or risky content before or after generation.</li>
<li><a href="../terms/safety-evaluation/">safety evaluation</a> — Testing focused on preventing harmful, abusive, or policy-violating AI behavior before and after launch.</li>
<li><a href="../terms/safety-review-board/">safety review board</a> — Cross-functional committee that approves high-risk AI launches and monitors mitigations.</li>
<li><a href="../terms/safety-spec/">safety spec</a> — Document that codifies allowed, disallowed, and escalated behaviours for an AI system so teams can enforce safety and policy expectations.</li>
<li><a href="../terms/self-critique-loop/">self-critique loop</a> — Pattern where a model reviews its own outputs, critiques them, and produces revisions before responding.</li>
<li><a href="../terms/shadow-deployment/">shadow deployment</a> — Deploying an AI system alongside the existing workflow without user impact to collect telemetry.</li>
<li><a href="../terms/synthetic-data/">synthetic data</a> — Artificially generated dataset used to augment training, testing, or privacy-preserving workflows.</li>
<li><a href="../terms/synthetic-data-evaluation/">synthetic data evaluation</a> — Process for measuring fidelity, utility, privacy, and bias of synthetic datasets before use.</li>
<li><a href="../terms/system-prompt/">system prompt</a> — Foundational instruction that sets role, tone, and guardrails for an AI assistant before user input.</li>
<li><a href="../terms/target-variable/">target variable</a> — Outcome the model is trained to predict, providing the signal for calculating loss.</li>
<li><a href="../terms/temperature/">temperature</a> — Decoding parameter that controls how random or deterministic a model’s outputs are.</li>
<li><a href="../terms/test-set/">test set</a> — Final evaluation split reserved for measuring real-world performance after all model tuning is finished.</li>
<li><a href="../terms/token/">token</a> — Smallest unit of text a model processes after tokenization, such as a word fragment or character.</li>
<li><a href="../terms/tool-use/">tool use</a> — Pattern where a model selects external tools or functions to handle parts of a task.</li>
<li><a href="../terms/top-k-sampling/">top-k sampling</a> — Decoding method that samples from the k most probable next tokens to balance diversity and control.</li>
<li><a href="../terms/top-p-sampling/">top-p sampling</a> — Decoding strategy that samples from the smallest set of tokens whose probabilities sum to p.</li>
<li><a href="../terms/training-data/">training data</a> — Labeled examples the model learns from before it ever sees validation or test inputs.</li>
<li><a href="../terms/transparency-report/">transparency report</a> — Periodic disclosure that details how an AI system operates, what data it handles, and how risks are mitigated.</li>
<li><a href="../terms/validation-set/">validation set</a> — Dataset slice used to tune hyperparameters and compare experiments without touching the test set.</li>
<li><a href="../terms/vector-store/">vector store</a> — Database optimized to store embeddings and execute similarity search over vectors.</li>
<li><a href="../terms/voice-cloning/">voice cloning</a> — Technique that replicates a person’s voice using generative models trained on audio samples.</li>
</ul>
<h2 id="engineering-platform">Engineering &amp; Platform<a class="headerlink" href="#engineering-platform" title="Permanent link">&para;</a></h2>
<p>Own model integration, infra, and technical debt.</p>
<p><strong>Action plan</strong>
- Bookmark the <a href="../search/">Glossary Search</a> filtered to this role and review the top 5 unfamiliar terms.
- Schedule a sync with partner roles listed under each term to clarify ownership and open questions.
- Capture insights in your runbook or onboarding guide so future teammates ramp faster.</p>
<h3 id="guided-learning-path_1">Guided learning path<a class="headerlink" href="#guided-learning-path_1" title="Permanent link">&para;</a></h3>
<ol>
<li>Start with LLM Core mechanics to understand knobs that affect reliability.</li>
<li>Review Operations &amp; Monitoring entries and note which metrics to add to dashboards.</li>
<li>Pair with policy leads on governance terms that require instrumentation support.</li>
</ol>
<h3 id="practice-checklist_1">Practice checklist<a class="headerlink" href="#practice-checklist_1" title="Permanent link">&para;</a></h3>
<ul>
<li>Use the search filters (engineering + operations) and capture metrics to wire into observability dashboards.</li>
<li>Document deployment actions in your runbook using examples referenced in the glossary.</li>
</ul>
<h3 id="focus-areas_1">Focus areas<a class="headerlink" href="#focus-areas_1" title="Permanent link">&para;</a></h3>
<ul>
<li>Governance &amp; Risk (29 terms)</li>
<li>LLM Core (26 terms)</li>
<li>Foundations (19 terms)</li>
<li>Operations &amp; Monitoring (18 terms)</li>
<li>Agents &amp; Tooling (7 terms)</li>
<li>Retrieval &amp; RAG (7 terms)</li>
<li>Optimization &amp; Efficiency (6 terms)</li>
</ul>
<h3 id="recommended-terms_1">Recommended terms<a class="headerlink" href="#recommended-terms_1" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="../terms/agent-executor/">agent executor</a> — Controller layer that schedules planning, tool calls, and stop conditions so an AI agent completes tasks safely.</li>
<li><a href="../terms/agentic-ai/">agentic ai</a> — Systems that plan, act, and iterate with minimal human prompts by chaining model calls and tools.</li>
<li><a href="../terms/ai-assurance/">ai assurance</a> — Discipline that produces evidence, controls, and attestations showing an AI system meets agreed safety, compliance, and performance thresholds.</li>
<li><a href="../terms/ai-circuit-breaker/">ai circuit breaker</a> — Automated control that halts model responses or tool access when risk thresholds are exceeded.</li>
<li><a href="../terms/ai-incident-response/">ai incident response</a> — Coordinated workflow for detecting, triaging, and remediating harmful or out-of-policy AI behavior.</li>
<li><a href="../terms/algorithmic-audit/">algorithmic audit</a> — Independent review of an AI system’s data, design, and outcomes to verify compliance, fairness, and risk controls.</li>
<li><a href="../terms/algorithmic-impact-assessment/">algorithmic impact assessment</a> — Structured review that documents how an AI system may affect people, processes, and compliance obligations.</li>
<li><a href="../terms/assurance-case/">assurance case</a> — Structured argument that proves an AI system meets safety and compliance expectations.</li>
<li><a href="../terms/attention/">attention</a> — Technique enabling models to weight input tokens differently when producing each output.</li>
<li><a href="../terms/beam-search/">beam search</a> — Deterministic decoding that keeps the top scoring sequences across multiple beams before selecting the final output.</li>
<li><a href="../terms/bias-variance-tradeoff/">bias-variance tradeoff</a> — Balance between underfitting and overfitting: low bias increases variance, while high bias lowers variance but misses patterns.</li>
<li><a href="../terms/chain-of-thought-prompting/">chain-of-thought prompting</a> — Prompting technique that asks models to reason through intermediate steps before giving a final answer.</li>
<li><a href="../terms/chunking/">chunking</a> — Splitting source documents into manageable pieces before indexing or feeding them to models.</li>
<li><a href="../terms/clip/">clip</a> — Multimodal model that embeds images and text into a shared space using contrastive learning.</li>
<li><a href="../terms/confusion-matrix/">confusion matrix</a> — Table that summarizes true/false positives and negatives to diagnose classification performance.</li>
<li><a href="../terms/consent-management/">consent management</a> — Practices that capture, honor, and audit user permissions across AI features.</li>
<li><a href="../terms/constitutional-ai/">constitutional ai</a> — Alignment approach where models critique and revise their own outputs against a written set of principles.</li>
<li><a href="../terms/content-moderation/">content moderation</a> — Workflows and tools that review, filter, and act on user-generated content to enforce policy.</li>
<li><a href="../terms/context-window/">context window</a> — Maximum number of tokens a model can consider at once during prompting or inference.</li>
<li><a href="../terms/cross-validation/">cross-validation</a> — Evaluation technique that splits data into multiple folds to estimate model performance on unseen samples.</li>
<li><a href="../terms/data-lineage/">data lineage</a> — Traceable record of how data moves, transforms, and is used across AI systems.</li>
<li><a href="../terms/data-redaction/">data redaction</a> — Removal or masking of sensitive fields before data is stored, shared, or used for model training.</li>
<li><a href="../terms/decoding/">decoding</a> — Algorithms that turn model probability distributions into output tokens during generation.</li>
<li><a href="../terms/differential-privacy/">differential privacy</a> — Mathematical framework that limits how much any single record influences published data or model outputs.</li>
<li><a href="../terms/diffusion-model/">diffusion model</a> — Generative model that iteratively denoises random noise to synthesize images, audio, or other data.</li>
<li><a href="../terms/direct-preference-optimization/">direct preference optimization</a> — Alignment technique that fine-tunes models directly on preference data without training a separate reward model.</li>
<li><a href="../terms/embedding/">embedding</a> — Dense numerical representation that captures semantic meaning of text, images, or other data.</li>
<li><a href="../terms/escalation-policy/">escalation policy</a> — Playbook that defines when and how AI systems route control to human reviewers.</li>
<li><a href="../terms/evaluation/">evaluation</a> — Systematic measurement of model performance, safety, and reliability using defined tests.</li>
<li><a href="../terms/evaluation-harness/">evaluation harness</a> — Automated pipeline that replays tasks, scores outputs, and reports regressions for AI systems.</li>
<li><a href="../terms/f1-score/">f1 score</a> — Harmonic mean of precision and recall, balancing false positives and false negatives.</li>
<li><a href="../terms/fairness-metrics/">fairness metrics</a> — Quantitative measures that evaluate whether model performance is equitable across groups.</li>
<li><a href="../terms/feature-engineering/">feature engineering</a> — Transforming raw data into model-ready features that improve signal, fairness, and maintainability.</li>
<li><a href="../terms/fine-tuning/">fine-tuning</a> — Additional training that adapts a pretrained model to a specific task or domain.</li>
<li><a href="../terms/function-calling/">function calling</a> — LLM capability that lets prompts invoke predefined functions and return structured arguments.</li>
<li><a href="../terms/generalization/">generalization</a> — Model's ability to sustain performance on unseen data rather than memorising the training set.</li>
<li><a href="../terms/gradient-descent/">gradient descent</a> — Iterative optimization algorithm that updates model parameters in the direction of the negative gradient to minimize a loss function.</li>
<li><a href="../terms/greedy-decoding/">greedy decoding</a> — Strategy that selects the highest-probability token at each step, producing deterministic outputs.</li>
<li><a href="../terms/guardrail-policy/">guardrail policy</a> — Documented rules and prompts that define allowed, blocked, and escalated behaviors for AI systems.</li>
<li><a href="../terms/hallucination/">hallucination</a> — When an AI model presents fabricated or unsupported information as fact.</li>
<li><a href="../terms/human-handoff/">human handoff</a> — Moment when an AI workflow transfers control to a human for review or action.</li>
<li><a href="../terms/impact-mitigation-plan/">impact mitigation plan</a> — Action plan that tracks risks, mitigations, owners, and timelines for an AI deployment.</li>
<li><a href="../terms/incident-taxonomy/">incident taxonomy</a> — Standardized categories used to tag, analyze, and report AI incidents consistently.</li>
<li><a href="../terms/instruction-tuning/">instruction tuning</a> — Supervised training that teaches models to follow natural-language instructions using curated examples.</li>
<li><a href="../terms/jailbreak-prompt/">jailbreak prompt</a> — Crafted input that persuades a model to ignore safety instructions and produce disallowed responses.</li>
<li><a href="../terms/knowledge-distillation/">knowledge distillation</a> — Technique that trains a smaller student model to mimic a larger teacher model’s behavior.</li>
<li><a href="../terms/kv-cache/">kv cache</a> — Stored attention keys and values reused across decoding steps to speed sequential generation.</li>
<li><a href="../terms/log-probability/">log probability</a> — Logarithm of a token’s probability, used to inspect model confidence and guide decoding tweaks.</li>
<li><a href="../terms/loss-function/">loss function</a> — Mathematical rule that scores how far model predictions deviate from desired targets.</li>
<li><a href="../terms/low-rank-adaptation/">low-rank adaptation</a> — Parameter-efficient fine-tuning that injects low-rank update matrices into transformer weights.</li>
<li><a href="../terms/memory-strategy/">memory strategy</a> — Deliberate approach for when an AI agent stores, retrieves, or forgets context across tasks.</li>
<li><a href="../terms/mixture-of-experts/">mixture of experts</a> — Neural architecture that routes tokens to specialized submodels to scale capacity efficiently.</li>
<li><a href="../terms/ml-observability/">ml observability</a> — Practices and tooling that surface model health through metrics, traces, and alerts across the lifecycle.</li>
<li><a href="../terms/ml-ops/">ml ops</a> — Operational discipline that manages ML models from experimentation through deployment and monitoring.</li>
<li><a href="../terms/model-card/">model card</a> — Standardized documentation describing a model’s purpose, data, performance, and limitations.</li>
<li><a href="../terms/model-drift/">model drift</a> — Gradual mismatch between model assumptions and real-world data that degrades performance over time.</li>
<li><a href="../terms/model-interpretability/">model interpretability</a> — Ability to explain how a model arrives at its predictions in ways stakeholders understand.</li>
<li><a href="../terms/overfitting/">overfitting</a> — When a model memorizes training data patterns so closely that it performs poorly on new samples.</li>
<li><a href="../terms/precision/">precision</a> — Share of predicted positives that are actually correct for a given classifier.</li>
<li><a href="../terms/preference-dataset/">preference dataset</a> — Labeled comparisons of model outputs that capture which responses humans prefer.</li>
<li><a href="../terms/privacy-budget/">privacy budget</a> — Quantitative limit on how much privacy loss is allowed when applying differential privacy.</li>
<li><a href="../terms/prompt-engineering/">prompt engineering</a> — Crafting and testing prompts to steer model behavior toward desired outcomes.</li>
<li><a href="../terms/prompt-injection/">prompt injection</a> — Attack that inserts malicious instructions into model inputs to override original prompts or policies.</li>
<li><a href="../terms/quantization/">quantization</a> — Technique that compresses model weights into lower-precision formats to shrink size and speed inference.</li>
<li><a href="../terms/recall/">recall</a> — Share of actual positives a model successfully identifies.</li>
<li><a href="../terms/red-teaming/">red teaming</a> — Deliberate stress testing that probes AI systems for harmful, biased, or policy-violating behavior.</li>
<li><a href="../terms/regularization/">regularization</a> — Techniques that add penalties or constraints during training to reduce overfitting and improve generalisation.</li>
<li><a href="../terms/reinforcement-learning-from-human-feedback/">reinforcement learning from human feedback</a> — Training approach that tunes a model using reward signals learned from human preference data.</li>
<li><a href="../terms/repetition-penalty/">repetition penalty</a> — Decoding adjustment that down-weights tokens already generated to reduce loops and repeated phrases.</li>
<li><a href="../terms/reranking/">reranking</a> — Step that refines retrieval results using a more precise but slower scoring model.</li>
<li><a href="../terms/retrieval/">retrieval</a> — Process of selecting relevant documents or vectors from a corpus in response to a query.</li>
<li><a href="../terms/retrieval-augmented-generation/">retrieval-augmented generation</a> — Workflow that grounds a generative model with retrieved context before producing output.</li>
<li><a href="../terms/reward-model/">reward model</a> — Model trained on human preferences that scores AI responses for alignment or quality.</li>
<li><a href="../terms/risk-register/">risk register</a> — Central list of identified AI risks, their owners, mitigations, and review status.</li>
<li><a href="../terms/robust-prompting/">robust prompting</a> — Prompt design techniques that harden models against injections, ambiguity, and unsafe outputs.</li>
<li><a href="../terms/roc-auc/">roc auc</a> — Metric summarizing binary classifier performance by measuring area under the ROC curve.</li>
<li><a href="../terms/safety-classifier/">safety classifier</a> — Model that detects policy-violating or risky content before or after generation.</li>
<li><a href="../terms/safety-evaluation/">safety evaluation</a> — Testing focused on preventing harmful, abusive, or policy-violating AI behavior before and after launch.</li>
<li><a href="../terms/safety-spec/">safety spec</a> — Document that codifies allowed, disallowed, and escalated behaviours for an AI system so teams can enforce safety and policy expectations.</li>
<li><a href="../terms/self-consistency-decoding/">self-consistency decoding</a> — Decoding strategy that samples multiple reasoning paths and aggregates the most consistent answer.</li>
<li><a href="../terms/self-critique-loop/">self-critique loop</a> — Pattern where a model reviews its own outputs, critiques them, and produces revisions before responding.</li>
<li><a href="../terms/shadow-deployment/">shadow deployment</a> — Deploying an AI system alongside the existing workflow without user impact to collect telemetry.</li>
<li><a href="../terms/synthetic-data/">synthetic data</a> — Artificially generated dataset used to augment training, testing, or privacy-preserving workflows.</li>
<li><a href="../terms/synthetic-data-evaluation/">synthetic data evaluation</a> — Process for measuring fidelity, utility, privacy, and bias of synthetic datasets before use.</li>
<li><a href="../terms/system-prompt/">system prompt</a> — Foundational instruction that sets role, tone, and guardrails for an AI assistant before user input.</li>
<li><a href="../terms/target-variable/">target variable</a> — Outcome the model is trained to predict, providing the signal for calculating loss.</li>
<li><a href="../terms/temperature/">temperature</a> — Decoding parameter that controls how random or deterministic a model’s outputs are.</li>
<li><a href="../terms/test-set/">test set</a> — Final evaluation split reserved for measuring real-world performance after all model tuning is finished.</li>
<li><a href="../terms/token/">token</a> — Smallest unit of text a model processes after tokenization, such as a word fragment or character.</li>
<li><a href="../terms/tool-use/">tool use</a> — Pattern where a model selects external tools or functions to handle parts of a task.</li>
<li><a href="../terms/top-k-sampling/">top-k sampling</a> — Decoding method that samples from the k most probable next tokens to balance diversity and control.</li>
<li><a href="../terms/top-p-sampling/">top-p sampling</a> — Decoding strategy that samples from the smallest set of tokens whose probabilities sum to p.</li>
<li><a href="../terms/training-data/">training data</a> — Labeled examples the model learns from before it ever sees validation or test inputs.</li>
<li><a href="../terms/validation-set/">validation set</a> — Dataset slice used to tune hyperparameters and compare experiments without touching the test set.</li>
<li><a href="../terms/vector-store/">vector store</a> — Database optimized to store embeddings and execute similarity search over vectors.</li>
</ul>
<h2 id="data-science-research">Data Science &amp; Research<a class="headerlink" href="#data-science-research" title="Permanent link">&para;</a></h2>
<p>Drive experimentation, measurement, and model improvement.</p>
<p><strong>Action plan</strong>
- Bookmark the <a href="../search/">Glossary Search</a> filtered to this role and review the top 5 unfamiliar terms.
- Schedule a sync with partner roles listed under each term to clarify ownership and open questions.
- Capture insights in your runbook or onboarding guide so future teammates ramp faster.</p>
<h3 id="guided-learning-path_2">Guided learning path<a class="headerlink" href="#guided-learning-path_2" title="Permanent link">&para;</a></h3>
<ol>
<li>Refresh foundational metrics (precision, recall, ROC AUC) to ensure evaluation coverage.</li>
<li>Study Optimization &amp; Efficiency techniques to plan future experiments.</li>
<li>Document how governance-aligned metrics will be reported to stakeholders.</li>
</ol>
<h3 id="practice-checklist_2">Practice checklist<a class="headerlink" href="#practice-checklist_2" title="Permanent link">&para;</a></h3>
<ul>
<li>Select one evaluation metric and one mitigation technique from the glossary for your next experiment brief.</li>
<li>Record baseline measurements tied to the definitions before shipping changes.</li>
</ul>
<h3 id="focus-areas_2">Focus areas<a class="headerlink" href="#focus-areas_2" title="Permanent link">&para;</a></h3>
<ul>
<li>LLM Core (23 terms)</li>
<li>Foundations (19 terms)</li>
<li>Retrieval &amp; RAG (7 terms)</li>
<li>Optimization &amp; Efficiency (6 terms)</li>
<li>Governance &amp; Risk (5 terms)</li>
<li>Operations &amp; Monitoring (4 terms)</li>
<li>Agents &amp; Tooling (1 term)</li>
</ul>
<h3 id="recommended-terms_2">Recommended terms<a class="headerlink" href="#recommended-terms_2" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="../terms/attention/">attention</a> — Technique enabling models to weight input tokens differently when producing each output.</li>
<li><a href="../terms/beam-search/">beam search</a> — Deterministic decoding that keeps the top scoring sequences across multiple beams before selecting the final output.</li>
<li><a href="../terms/bias-variance-tradeoff/">bias-variance tradeoff</a> — Balance between underfitting and overfitting: low bias increases variance, while high bias lowers variance but misses patterns.</li>
<li><a href="../terms/chain-of-thought-prompting/">chain-of-thought prompting</a> — Prompting technique that asks models to reason through intermediate steps before giving a final answer.</li>
<li><a href="../terms/chunking/">chunking</a> — Splitting source documents into manageable pieces before indexing or feeding them to models.</li>
<li><a href="../terms/clip/">clip</a> — Multimodal model that embeds images and text into a shared space using contrastive learning.</li>
<li><a href="../terms/confusion-matrix/">confusion matrix</a> — Table that summarizes true/false positives and negatives to diagnose classification performance.</li>
<li><a href="../terms/context-window/">context window</a> — Maximum number of tokens a model can consider at once during prompting or inference.</li>
<li><a href="../terms/cross-validation/">cross-validation</a> — Evaluation technique that splits data into multiple folds to estimate model performance on unseen samples.</li>
<li><a href="../terms/data-lineage/">data lineage</a> — Traceable record of how data moves, transforms, and is used across AI systems.</li>
<li><a href="../terms/dataset-card/">dataset card</a> — Structured documentation describing a dataset’s purpose, composition, risks, and usage constraints.</li>
<li><a href="../terms/decoding/">decoding</a> — Algorithms that turn model probability distributions into output tokens during generation.</li>
<li><a href="../terms/diffusion-model/">diffusion model</a> — Generative model that iteratively denoises random noise to synthesize images, audio, or other data.</li>
<li><a href="../terms/direct-preference-optimization/">direct preference optimization</a> — Alignment technique that fine-tunes models directly on preference data without training a separate reward model.</li>
<li><a href="../terms/embedding/">embedding</a> — Dense numerical representation that captures semantic meaning of text, images, or other data.</li>
<li><a href="../terms/evaluation-harness/">evaluation harness</a> — Automated pipeline that replays tasks, scores outputs, and reports regressions for AI systems.</li>
<li><a href="../terms/f1-score/">f1 score</a> — Harmonic mean of precision and recall, balancing false positives and false negatives.</li>
<li><a href="../terms/feature-engineering/">feature engineering</a> — Transforming raw data into model-ready features that improve signal, fairness, and maintainability.</li>
<li><a href="../terms/fine-tuning/">fine-tuning</a> — Additional training that adapts a pretrained model to a specific task or domain.</li>
<li><a href="../terms/function-calling/">function calling</a> — LLM capability that lets prompts invoke predefined functions and return structured arguments.</li>
<li><a href="../terms/generalization/">generalization</a> — Model's ability to sustain performance on unseen data rather than memorising the training set.</li>
<li><a href="../terms/gradient-descent/">gradient descent</a> — Iterative optimization algorithm that updates model parameters in the direction of the negative gradient to minimize a loss function.</li>
<li><a href="../terms/greedy-decoding/">greedy decoding</a> — Strategy that selects the highest-probability token at each step, producing deterministic outputs.</li>
<li><a href="../terms/hallucination/">hallucination</a> — When an AI model presents fabricated or unsupported information as fact.</li>
<li><a href="../terms/instruction-tuning/">instruction tuning</a> — Supervised training that teaches models to follow natural-language instructions using curated examples.</li>
<li><a href="../terms/knowledge-distillation/">knowledge distillation</a> — Technique that trains a smaller student model to mimic a larger teacher model’s behavior.</li>
<li><a href="../terms/kv-cache/">kv cache</a> — Stored attention keys and values reused across decoding steps to speed sequential generation.</li>
<li><a href="../terms/log-probability/">log probability</a> — Logarithm of a token’s probability, used to inspect model confidence and guide decoding tweaks.</li>
<li><a href="../terms/loss-function/">loss function</a> — Mathematical rule that scores how far model predictions deviate from desired targets.</li>
<li><a href="../terms/low-rank-adaptation/">low-rank adaptation</a> — Parameter-efficient fine-tuning that injects low-rank update matrices into transformer weights.</li>
<li><a href="../terms/mixture-of-experts/">mixture of experts</a> — Neural architecture that routes tokens to specialized submodels to scale capacity efficiently.</li>
<li><a href="../terms/overfitting/">overfitting</a> — When a model memorizes training data patterns so closely that it performs poorly on new samples.</li>
<li><a href="../terms/precision/">precision</a> — Share of predicted positives that are actually correct for a given classifier.</li>
<li><a href="../terms/preference-dataset/">preference dataset</a> — Labeled comparisons of model outputs that capture which responses humans prefer.</li>
<li><a href="../terms/privacy-budget/">privacy budget</a> — Quantitative limit on how much privacy loss is allowed when applying differential privacy.</li>
<li><a href="../terms/prompt-engineering/">prompt engineering</a> — Crafting and testing prompts to steer model behavior toward desired outcomes.</li>
<li><a href="../terms/quantization/">quantization</a> — Technique that compresses model weights into lower-precision formats to shrink size and speed inference.</li>
<li><a href="../terms/recall/">recall</a> — Share of actual positives a model successfully identifies.</li>
<li><a href="../terms/regularization/">regularization</a> — Techniques that add penalties or constraints during training to reduce overfitting and improve generalisation.</li>
<li><a href="../terms/reinforcement-learning-from-human-feedback/">reinforcement learning from human feedback</a> — Training approach that tunes a model using reward signals learned from human preference data.</li>
<li><a href="../terms/repetition-penalty/">repetition penalty</a> — Decoding adjustment that down-weights tokens already generated to reduce loops and repeated phrases.</li>
<li><a href="../terms/reranking/">reranking</a> — Step that refines retrieval results using a more precise but slower scoring model.</li>
<li><a href="../terms/retrieval/">retrieval</a> — Process of selecting relevant documents or vectors from a corpus in response to a query.</li>
<li><a href="../terms/retrieval-augmented-generation/">retrieval-augmented generation</a> — Workflow that grounds a generative model with retrieved context before producing output.</li>
<li><a href="../terms/reward-model/">reward model</a> — Model trained on human preferences that scores AI responses for alignment or quality.</li>
<li><a href="../terms/roc-auc/">roc auc</a> — Metric summarizing binary classifier performance by measuring area under the ROC curve.</li>
<li><a href="../terms/self-consistency-decoding/">self-consistency decoding</a> — Decoding strategy that samples multiple reasoning paths and aggregates the most consistent answer.</li>
<li><a href="../terms/synthetic-data/">synthetic data</a> — Artificially generated dataset used to augment training, testing, or privacy-preserving workflows.</li>
<li><a href="../terms/synthetic-data-evaluation/">synthetic data evaluation</a> — Process for measuring fidelity, utility, privacy, and bias of synthetic datasets before use.</li>
<li><a href="../terms/system-prompt/">system prompt</a> — Foundational instruction that sets role, tone, and guardrails for an AI assistant before user input.</li>
<li><a href="../terms/target-variable/">target variable</a> — Outcome the model is trained to predict, providing the signal for calculating loss.</li>
<li><a href="../terms/temperature/">temperature</a> — Decoding parameter that controls how random or deterministic a model’s outputs are.</li>
<li><a href="../terms/test-set/">test set</a> — Final evaluation split reserved for measuring real-world performance after all model tuning is finished.</li>
<li><a href="../terms/token/">token</a> — Smallest unit of text a model processes after tokenization, such as a word fragment or character.</li>
<li><a href="../terms/top-k-sampling/">top-k sampling</a> — Decoding method that samples from the k most probable next tokens to balance diversity and control.</li>
<li><a href="../terms/top-p-sampling/">top-p sampling</a> — Decoding strategy that samples from the smallest set of tokens whose probabilities sum to p.</li>
<li><a href="../terms/training-data/">training data</a> — Labeled examples the model learns from before it ever sees validation or test inputs.</li>
<li><a href="../terms/validation-set/">validation set</a> — Dataset slice used to tune hyperparameters and compare experiments without touching the test set.</li>
<li><a href="../terms/vector-store/">vector store</a> — Database optimized to store embeddings and execute similarity search over vectors.</li>
</ul>
<h2 id="policy-risk">Policy &amp; Risk<a class="headerlink" href="#policy-risk" title="Permanent link">&para;</a></h2>
<p>Ensure responsible AI controls align with governance frameworks.</p>
<p><strong>Action plan</strong>
- Bookmark the <a href="../search/">Glossary Search</a> filtered to this role and review the top 5 unfamiliar terms.
- Schedule a sync with partner roles listed under each term to clarify ownership and open questions.
- Capture insights in your runbook or onboarding guide so future teammates ramp faster.</p>
<h3 id="guided-learning-path_3">Guided learning path<a class="headerlink" href="#guided-learning-path_3" title="Permanent link">&para;</a></h3>
<ol>
<li>Read algorithmic governance terms to map glossary content to internal controls.</li>
<li>Identify three technical concepts to discuss with engineering for upcoming reviews.</li>
<li>Draft guidance for disclosure or transparency using relevant glossary examples.</li>
</ol>
<h3 id="practice-checklist_3">Practice checklist<a class="headerlink" href="#practice-checklist_3" title="Permanent link">&para;</a></h3>
<ul>
<li>Draft a review checklist referencing the top three governance terms surfaced in the backlog.</li>
<li>Map required disclosures for the next launch memo using linked glossary examples.</li>
</ul>
<h3 id="focus-areas_3">Focus areas<a class="headerlink" href="#focus-areas_3" title="Permanent link">&para;</a></h3>
<ul>
<li>Governance &amp; Risk (40 terms)</li>
<li>Operations &amp; Monitoring (17 terms)</li>
<li>Foundations (7 terms)</li>
<li>LLM Core (6 terms)</li>
<li>Agents &amp; Tooling (2 terms)</li>
<li>Optimization &amp; Efficiency (1 term)</li>
<li>Retrieval &amp; RAG (1 term)</li>
</ul>
<h3 id="recommended-terms_3">Recommended terms<a class="headerlink" href="#recommended-terms_3" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="../terms/ai-assurance/">ai assurance</a> — Discipline that produces evidence, controls, and attestations showing an AI system meets agreed safety, compliance, and performance thresholds.</li>
<li><a href="../terms/ai-circuit-breaker/">ai circuit breaker</a> — Automated control that halts model responses or tool access when risk thresholds are exceeded.</li>
<li><a href="../terms/ai-incident-response/">ai incident response</a> — Coordinated workflow for detecting, triaging, and remediating harmful or out-of-policy AI behavior.</li>
<li><a href="../terms/algorithmic-audit/">algorithmic audit</a> — Independent review of an AI system’s data, design, and outcomes to verify compliance, fairness, and risk controls.</li>
<li><a href="../terms/algorithmic-bias/">algorithmic bias</a> — Systematic unfairness in model outputs that disadvantages certain groups or outcomes.</li>
<li><a href="../terms/algorithmic-impact-assessment/">algorithmic impact assessment</a> — Structured review that documents how an AI system may affect people, processes, and compliance obligations.</li>
<li><a href="../terms/alignment/">alignment</a> — Making sure AI systems optimize for human values, policies, and intended outcomes.</li>
<li><a href="../terms/assurance-case/">assurance case</a> — Structured argument that proves an AI system meets safety and compliance expectations.</li>
<li><a href="../terms/bias-variance-tradeoff/">bias-variance tradeoff</a> — Balance between underfitting and overfitting: low bias increases variance, while high bias lowers variance but misses patterns.</li>
<li><a href="../terms/confusion-matrix/">confusion matrix</a> — Table that summarizes true/false positives and negatives to diagnose classification performance.</li>
<li><a href="../terms/consent-management/">consent management</a> — Practices that capture, honor, and audit user permissions across AI features.</li>
<li><a href="../terms/constitutional-ai/">constitutional ai</a> — Alignment approach where models critique and revise their own outputs against a written set of principles.</li>
<li><a href="../terms/content-moderation/">content moderation</a> — Workflows and tools that review, filter, and act on user-generated content to enforce policy.</li>
<li><a href="../terms/data-lineage/">data lineage</a> — Traceable record of how data moves, transforms, and is used across AI systems.</li>
<li><a href="../terms/data-minimization/">data minimization</a> — Principle of collecting and retaining only the data necessary for a defined purpose.</li>
<li><a href="../terms/data-redaction/">data redaction</a> — Removal or masking of sensitive fields before data is stored, shared, or used for model training.</li>
<li><a href="../terms/data-retention/">data retention</a> — Policies defining how long data is stored, where it lives, and how it is deleted.</li>
<li><a href="../terms/dataset-card/">dataset card</a> — Structured documentation describing a dataset’s purpose, composition, risks, and usage constraints.</li>
<li><a href="../terms/differential-privacy/">differential privacy</a> — Mathematical framework that limits how much any single record influences published data or model outputs.</li>
<li><a href="../terms/escalation-policy/">escalation policy</a> — Playbook that defines when and how AI systems route control to human reviewers.</li>
<li><a href="../terms/evaluation/">evaluation</a> — Systematic measurement of model performance, safety, and reliability using defined tests.</li>
<li><a href="../terms/fairness-metrics/">fairness metrics</a> — Quantitative measures that evaluate whether model performance is equitable across groups.</li>
<li><a href="../terms/generative-ai/">generative ai</a> — Family of models that produce new content—text, images, code—rather than only making predictions.</li>
<li><a href="../terms/guardrail-policy/">guardrail policy</a> — Documented rules and prompts that define allowed, blocked, and escalated behaviors for AI systems.</li>
<li><a href="../terms/guardrails/">guardrails</a> — Controls that constrain model behavior to comply with safety, legal, or brand requirements.</li>
<li><a href="../terms/hallucination/">hallucination</a> — When an AI model presents fabricated or unsupported information as fact.</li>
<li><a href="../terms/human-handoff/">human handoff</a> — Moment when an AI workflow transfers control to a human for review or action.</li>
<li><a href="../terms/impact-mitigation-plan/">impact mitigation plan</a> — Action plan that tracks risks, mitigations, owners, and timelines for an AI deployment.</li>
<li><a href="../terms/incident-taxonomy/">incident taxonomy</a> — Standardized categories used to tag, analyze, and report AI incidents consistently.</li>
<li><a href="../terms/instruction-tuning/">instruction tuning</a> — Supervised training that teaches models to follow natural-language instructions using curated examples.</li>
<li><a href="../terms/loss-function/">loss function</a> — Mathematical rule that scores how far model predictions deviate from desired targets.</li>
<li><a href="../terms/ml-observability/">ml observability</a> — Practices and tooling that surface model health through metrics, traces, and alerts across the lifecycle.</li>
<li><a href="../terms/ml-ops/">ml ops</a> — Operational discipline that manages ML models from experimentation through deployment and monitoring.</li>
<li><a href="../terms/model-card/">model card</a> — Standardized documentation describing a model’s purpose, data, performance, and limitations.</li>
<li><a href="../terms/model-drift/">model drift</a> — Gradual mismatch between model assumptions and real-world data that degrades performance over time.</li>
<li><a href="../terms/model-governance/">model governance</a> — Policies and processes that manage AI models across risk, compliance, and lifecycle decisions.</li>
<li><a href="../terms/model-interpretability/">model interpretability</a> — Ability to explain how a model arrives at its predictions in ways stakeholders understand.</li>
<li><a href="../terms/precision/">precision</a> — Share of predicted positives that are actually correct for a given classifier.</li>
<li><a href="../terms/preference-dataset/">preference dataset</a> — Labeled comparisons of model outputs that capture which responses humans prefer.</li>
<li><a href="../terms/privacy/">privacy</a> — Principle of limiting data collection, use, and exposure to protect individuals’ information.</li>
<li><a href="../terms/privacy-budget/">privacy budget</a> — Quantitative limit on how much privacy loss is allowed when applying differential privacy.</li>
<li><a href="../terms/privacy-impact-assessment/">privacy impact assessment</a> — Structured review that evaluates how a system collects, uses, and safeguards personal data.</li>
<li><a href="../terms/recall/">recall</a> — Share of actual positives a model successfully identifies.</li>
<li><a href="../terms/red-teaming/">red teaming</a> — Deliberate stress testing that probes AI systems for harmful, biased, or policy-violating behavior.</li>
<li><a href="../terms/reinforcement-learning-from-human-feedback/">reinforcement learning from human feedback</a> — Training approach that tunes a model using reward signals learned from human preference data.</li>
<li><a href="../terms/responsible-ai/">responsible ai</a> — Frameworks and practices that ensure AI systems are safe, fair, and aligned with ethical and legal expectations.</li>
<li><a href="../terms/retrieval/">retrieval</a> — Process of selecting relevant documents or vectors from a corpus in response to a query.</li>
<li><a href="../terms/reward-model/">reward model</a> — Model trained on human preferences that scores AI responses for alignment or quality.</li>
<li><a href="../terms/risk-register/">risk register</a> — Central list of identified AI risks, their owners, mitigations, and review status.</li>
<li><a href="../terms/safety-classifier/">safety classifier</a> — Model that detects policy-violating or risky content before or after generation.</li>
<li><a href="../terms/safety-evaluation/">safety evaluation</a> — Testing focused on preventing harmful, abusive, or policy-violating AI behavior before and after launch.</li>
<li><a href="../terms/safety-review-board/">safety review board</a> — Cross-functional committee that approves high-risk AI launches and monitors mitigations.</li>
<li><a href="../terms/safety-spec/">safety spec</a> — Document that codifies allowed, disallowed, and escalated behaviours for an AI system so teams can enforce safety and policy expectations.</li>
<li><a href="../terms/self-critique-loop/">self-critique loop</a> — Pattern where a model reviews its own outputs, critiques them, and produces revisions before responding.</li>
<li><a href="../terms/shadow-deployment/">shadow deployment</a> — Deploying an AI system alongside the existing workflow without user impact to collect telemetry.</li>
<li><a href="../terms/synthetic-data/">synthetic data</a> — Artificially generated dataset used to augment training, testing, or privacy-preserving workflows.</li>
<li><a href="../terms/synthetic-data-evaluation/">synthetic data evaluation</a> — Process for measuring fidelity, utility, privacy, and bias of synthetic datasets before use.</li>
<li><a href="../terms/transparency-report/">transparency report</a> — Periodic disclosure that details how an AI system operates, what data it handles, and how risks are mitigated.</li>
<li><a href="../terms/voice-cloning/">voice cloning</a> — Technique that replicates a person’s voice using generative models trained on audio samples.</li>
</ul>
<h2 id="legal-compliance">Legal &amp; Compliance<a class="headerlink" href="#legal-compliance" title="Permanent link">&para;</a></h2>
<p>Evaluate regulatory exposure, contracts, and IP concerns.</p>
<p><strong>Action plan</strong>
- Bookmark the <a href="../search/">Glossary Search</a> filtered to this role and review the top 5 unfamiliar terms.
- Schedule a sync with partner roles listed under each term to clarify ownership and open questions.
- Capture insights in your runbook or onboarding guide so future teammates ramp faster.</p>
<h3 id="guided-learning-path_4">Guided learning path<a class="headerlink" href="#guided-learning-path_4" title="Permanent link">&para;</a></h3>
<ol>
<li>Focus on Responsible AI and compliance-related terms to spot regulatory hooks.</li>
<li>Cross-reference privacy-focused entries with current policy language.</li>
<li>Capture open questions for the next risk or contract review cycle.</li>
</ol>
<h3 id="practice-checklist_4">Practice checklist<a class="headerlink" href="#practice-checklist_4" title="Permanent link">&para;</a></h3>
<ul>
<li>Compare contractual language with glossary definitions for privacy and retention to spot gaps.</li>
<li>Flag terms needing legal guidance through the intake form so questions are tracked.</li>
</ul>
<h3 id="focus-areas_4">Focus areas<a class="headerlink" href="#focus-areas_4" title="Permanent link">&para;</a></h3>
<ul>
<li>Governance &amp; Risk (31 terms)</li>
<li>Operations &amp; Monitoring (8 terms)</li>
<li>Foundations (1 term)</li>
<li>LLM Core (1 term)</li>
</ul>
<h3 id="recommended-terms_4">Recommended terms<a class="headerlink" href="#recommended-terms_4" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="../terms/ai-assurance/">ai assurance</a> — Discipline that produces evidence, controls, and attestations showing an AI system meets agreed safety, compliance, and performance thresholds.</li>
<li><a href="../terms/ai-incident-response/">ai incident response</a> — Coordinated workflow for detecting, triaging, and remediating harmful or out-of-policy AI behavior.</li>
<li><a href="../terms/algorithmic-audit/">algorithmic audit</a> — Independent review of an AI system’s data, design, and outcomes to verify compliance, fairness, and risk controls.</li>
<li><a href="../terms/algorithmic-bias/">algorithmic bias</a> — Systematic unfairness in model outputs that disadvantages certain groups or outcomes.</li>
<li><a href="../terms/algorithmic-impact-assessment/">algorithmic impact assessment</a> — Structured review that documents how an AI system may affect people, processes, and compliance obligations.</li>
<li><a href="../terms/alignment/">alignment</a> — Making sure AI systems optimize for human values, policies, and intended outcomes.</li>
<li><a href="../terms/assurance-case/">assurance case</a> — Structured argument that proves an AI system meets safety and compliance expectations.</li>
<li><a href="../terms/consent-management/">consent management</a> — Practices that capture, honor, and audit user permissions across AI features.</li>
<li><a href="../terms/data-lineage/">data lineage</a> — Traceable record of how data moves, transforms, and is used across AI systems.</li>
<li><a href="../terms/data-minimization/">data minimization</a> — Principle of collecting and retaining only the data necessary for a defined purpose.</li>
<li><a href="../terms/data-redaction/">data redaction</a> — Removal or masking of sensitive fields before data is stored, shared, or used for model training.</li>
<li><a href="../terms/data-retention/">data retention</a> — Policies defining how long data is stored, where it lives, and how it is deleted.</li>
<li><a href="../terms/dataset-card/">dataset card</a> — Structured documentation describing a dataset’s purpose, composition, risks, and usage constraints.</li>
<li><a href="../terms/differential-privacy/">differential privacy</a> — Mathematical framework that limits how much any single record influences published data or model outputs.</li>
<li><a href="../terms/evaluation/">evaluation</a> — Systematic measurement of model performance, safety, and reliability using defined tests.</li>
<li><a href="../terms/fairness-metrics/">fairness metrics</a> — Quantitative measures that evaluate whether model performance is equitable across groups.</li>
<li><a href="../terms/guardrails/">guardrails</a> — Controls that constrain model behavior to comply with safety, legal, or brand requirements.</li>
<li><a href="../terms/hallucination/">hallucination</a> — When an AI model presents fabricated or unsupported information as fact.</li>
<li><a href="../terms/impact-mitigation-plan/">impact mitigation plan</a> — Action plan that tracks risks, mitigations, owners, and timelines for an AI deployment.</li>
<li><a href="../terms/model-card/">model card</a> — Standardized documentation describing a model’s purpose, data, performance, and limitations.</li>
<li><a href="../terms/model-drift/">model drift</a> — Gradual mismatch between model assumptions and real-world data that degrades performance over time.</li>
<li><a href="../terms/model-governance/">model governance</a> — Policies and processes that manage AI models across risk, compliance, and lifecycle decisions.</li>
<li><a href="../terms/model-interpretability/">model interpretability</a> — Ability to explain how a model arrives at its predictions in ways stakeholders understand.</li>
<li><a href="../terms/privacy/">privacy</a> — Principle of limiting data collection, use, and exposure to protect individuals’ information.</li>
<li><a href="../terms/privacy-budget/">privacy budget</a> — Quantitative limit on how much privacy loss is allowed when applying differential privacy.</li>
<li><a href="../terms/privacy-impact-assessment/">privacy impact assessment</a> — Structured review that evaluates how a system collects, uses, and safeguards personal data.</li>
<li><a href="../terms/red-teaming/">red teaming</a> — Deliberate stress testing that probes AI systems for harmful, biased, or policy-violating behavior.</li>
<li><a href="../terms/responsible-ai/">responsible ai</a> — Frameworks and practices that ensure AI systems are safe, fair, and aligned with ethical and legal expectations.</li>
<li><a href="../terms/risk-register/">risk register</a> — Central list of identified AI risks, their owners, mitigations, and review status.</li>
<li><a href="../terms/safety-review-board/">safety review board</a> — Cross-functional committee that approves high-risk AI launches and monitors mitigations.</li>
<li><a href="../terms/transparency-report/">transparency report</a> — Periodic disclosure that details how an AI system operates, what data it handles, and how risks are mitigated.</li>
<li><a href="../terms/voice-cloning/">voice cloning</a> — Technique that replicates a person’s voice using generative models trained on audio samples.</li>
</ul>
<h2 id="security-trust">Security &amp; Trust<a class="headerlink" href="#security-trust" title="Permanent link">&para;</a></h2>
<p>Safeguard data, access, and abuse prevention.</p>
<p><strong>Action plan</strong>
- Bookmark the <a href="../search/">Glossary Search</a> filtered to this role and review the top 5 unfamiliar terms.
- Schedule a sync with partner roles listed under each term to clarify ownership and open questions.
- Capture insights in your runbook or onboarding guide so future teammates ramp faster.</p>
<h3 id="guided-learning-path_5">Guided learning path<a class="headerlink" href="#guided-learning-path_5" title="Permanent link">&para;</a></h3>
<ol>
<li>Study Operations &amp; Monitoring entries for logging and detection requirements.</li>
<li>Review tool and agent terminology to assess abuse surface areas.</li>
<li>Coordinate with product/legal on incident response and disclosure expectations.</li>
</ol>
<h3 id="practice-checklist_5">Practice checklist<a class="headerlink" href="#practice-checklist_5" title="Permanent link">&para;</a></h3>
<ul>
<li>Audit incident response and tool-use entries to confirm abuse-prevention controls are documented.</li>
<li>Plan a tabletop exercise using the glossary's scenario examples and log outcomes.</li>
</ul>
<h3 id="focus-areas_5">Focus areas<a class="headerlink" href="#focus-areas_5" title="Permanent link">&para;</a></h3>
<ul>
<li>Governance &amp; Risk (21 terms)</li>
<li>Operations &amp; Monitoring (11 terms)</li>
<li>LLM Core (2 terms)</li>
<li>Foundations (1 term)</li>
<li>Retrieval &amp; RAG (1 term)</li>
</ul>
<h3 id="recommended-terms_5">Recommended terms<a class="headerlink" href="#recommended-terms_5" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="../terms/ai-assurance/">ai assurance</a> — Discipline that produces evidence, controls, and attestations showing an AI system meets agreed safety, compliance, and performance thresholds.</li>
<li><a href="../terms/ai-circuit-breaker/">ai circuit breaker</a> — Automated control that halts model responses or tool access when risk thresholds are exceeded.</li>
<li><a href="../terms/ai-incident-response/">ai incident response</a> — Coordinated workflow for detecting, triaging, and remediating harmful or out-of-policy AI behavior.</li>
<li><a href="../terms/algorithmic-bias/">algorithmic bias</a> — Systematic unfairness in model outputs that disadvantages certain groups or outcomes.</li>
<li><a href="../terms/content-moderation/">content moderation</a> — Workflows and tools that review, filter, and act on user-generated content to enforce policy.</li>
<li><a href="../terms/data-minimization/">data minimization</a> — Principle of collecting and retaining only the data necessary for a defined purpose.</li>
<li><a href="../terms/data-redaction/">data redaction</a> — Removal or masking of sensitive fields before data is stored, shared, or used for model training.</li>
<li><a href="../terms/data-retention/">data retention</a> — Policies defining how long data is stored, where it lives, and how it is deleted.</li>
<li><a href="../terms/differential-privacy/">differential privacy</a> — Mathematical framework that limits how much any single record influences published data or model outputs.</li>
<li><a href="../terms/escalation-policy/">escalation policy</a> — Playbook that defines when and how AI systems route control to human reviewers.</li>
<li><a href="../terms/evaluation/">evaluation</a> — Systematic measurement of model performance, safety, and reliability using defined tests.</li>
<li><a href="../terms/guardrail-policy/">guardrail policy</a> — Documented rules and prompts that define allowed, blocked, and escalated behaviors for AI systems.</li>
<li><a href="../terms/incident-taxonomy/">incident taxonomy</a> — Standardized categories used to tag, analyze, and report AI incidents consistently.</li>
<li><a href="../terms/jailbreak-prompt/">jailbreak prompt</a> — Crafted input that persuades a model to ignore safety instructions and produce disallowed responses.</li>
<li><a href="../terms/ml-observability/">ml observability</a> — Practices and tooling that surface model health through metrics, traces, and alerts across the lifecycle.</li>
<li><a href="../terms/ml-ops/">ml ops</a> — Operational discipline that manages ML models from experimentation through deployment and monitoring.</li>
<li><a href="../terms/model-drift/">model drift</a> — Gradual mismatch between model assumptions and real-world data that degrades performance over time.</li>
<li><a href="../terms/privacy-impact-assessment/">privacy impact assessment</a> — Structured review that evaluates how a system collects, uses, and safeguards personal data.</li>
<li><a href="../terms/prompt-injection/">prompt injection</a> — Attack that inserts malicious instructions into model inputs to override original prompts or policies.</li>
<li><a href="../terms/red-teaming/">red teaming</a> — Deliberate stress testing that probes AI systems for harmful, biased, or policy-violating behavior.</li>
<li><a href="../terms/retrieval/">retrieval</a> — Process of selecting relevant documents or vectors from a corpus in response to a query.</li>
<li><a href="../terms/robust-prompting/">robust prompting</a> — Prompt design techniques that harden models against injections, ambiguity, and unsafe outputs.</li>
<li><a href="../terms/safety-classifier/">safety classifier</a> — Model that detects policy-violating or risky content before or after generation.</li>
<li><a href="../terms/safety-review-board/">safety review board</a> — Cross-functional committee that approves high-risk AI launches and monitors mitigations.</li>
<li><a href="../terms/safety-spec/">safety spec</a> — Document that codifies allowed, disallowed, and escalated behaviours for an AI system so teams can enforce safety and policy expectations.</li>
<li><a href="../terms/shadow-deployment/">shadow deployment</a> — Deploying an AI system alongside the existing workflow without user impact to collect telemetry.</li>
<li><a href="../terms/synthetic-data/">synthetic data</a> — Artificially generated dataset used to augment training, testing, or privacy-preserving workflows.</li>
<li><a href="../terms/voice-cloning/">voice cloning</a> — Technique that replicates a person’s voice using generative models trained on audio samples.</li>
</ul>
<h2 id="communications-enablement">Communications &amp; Enablement<a class="headerlink" href="#communications-enablement" title="Permanent link">&para;</a></h2>
<p>Craft messaging, disclosure, and stakeholder education.</p>
<p><strong>Action plan</strong>
- Bookmark the <a href="../search/">Glossary Search</a> filtered to this role and review the top 5 unfamiliar terms.
- Schedule a sync with partner roles listed under each term to clarify ownership and open questions.
- Capture insights in your runbook or onboarding guide so future teammates ramp faster.</p>
<h3 id="guided-learning-path_6">Guided learning path<a class="headerlink" href="#guided-learning-path_6" title="Permanent link">&para;</a></h3>
<ol>
<li>Scan definitions tagged for Governance &amp; Risk to prep stakeholder messaging.</li>
<li>Collect relatable examples from the glossary to use in enablement materials.</li>
<li>Draft a narrative that links technical terms to user-facing value and risk mitigations.</li>
</ol>
<h3 id="practice-checklist_6">Practice checklist<a class="headerlink" href="#practice-checklist_6" title="Permanent link">&para;</a></h3>
<ul>
<li>Draft an FAQ using glossary language to keep messaging consistent across teams.</li>
<li>Tag enablement tickets with relevant glossary links so stakeholders can self-serve context.</li>
</ul>
<h3 id="focus-areas_6">Focus areas<a class="headerlink" href="#focus-areas_6" title="Permanent link">&para;</a></h3>
<ul>
<li>Governance &amp; Risk (19 terms)</li>
<li>Operations &amp; Monitoring (7 terms)</li>
<li>Foundations (4 terms)</li>
<li>LLM Core (3 terms)</li>
<li>Retrieval &amp; RAG (2 terms)</li>
<li>Agents &amp; Tooling (1 term)</li>
</ul>
<h3 id="recommended-terms_6">Recommended terms<a class="headerlink" href="#recommended-terms_6" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="../terms/ai-incident-response/">ai incident response</a> — Coordinated workflow for detecting, triaging, and remediating harmful or out-of-policy AI behavior.</li>
<li><a href="../terms/algorithmic-audit/">algorithmic audit</a> — Independent review of an AI system’s data, design, and outcomes to verify compliance, fairness, and risk controls.</li>
<li><a href="../terms/algorithmic-bias/">algorithmic bias</a> — Systematic unfairness in model outputs that disadvantages certain groups or outcomes.</li>
<li><a href="../terms/algorithmic-impact-assessment/">algorithmic impact assessment</a> — Structured review that documents how an AI system may affect people, processes, and compliance obligations.</li>
<li><a href="../terms/alignment/">alignment</a> — Making sure AI systems optimize for human values, policies, and intended outcomes.</li>
<li><a href="../terms/clip/">clip</a> — Multimodal model that embeds images and text into a shared space using contrastive learning.</li>
<li><a href="../terms/content-moderation/">content moderation</a> — Workflows and tools that review, filter, and act on user-generated content to enforce policy.</li>
<li><a href="../terms/diffusion-model/">diffusion model</a> — Generative model that iteratively denoises random noise to synthesize images, audio, or other data.</li>
<li><a href="../terms/evaluation/">evaluation</a> — Systematic measurement of model performance, safety, and reliability using defined tests.</li>
<li><a href="../terms/generative-ai/">generative ai</a> — Family of models that produce new content—text, images, code—rather than only making predictions.</li>
<li><a href="../terms/guardrails/">guardrails</a> — Controls that constrain model behavior to comply with safety, legal, or brand requirements.</li>
<li><a href="../terms/hallucination/">hallucination</a> — When an AI model presents fabricated or unsupported information as fact.</li>
<li><a href="../terms/human-handoff/">human handoff</a> — Moment when an AI workflow transfers control to a human for review or action.</li>
<li><a href="../terms/model-card/">model card</a> — Standardized documentation describing a model’s purpose, data, performance, and limitations.</li>
<li><a href="../terms/model-drift/">model drift</a> — Gradual mismatch between model assumptions and real-world data that degrades performance over time.</li>
<li><a href="../terms/model-governance/">model governance</a> — Policies and processes that manage AI models across risk, compliance, and lifecycle decisions.</li>
<li><a href="../terms/privacy/">privacy</a> — Principle of limiting data collection, use, and exposure to protect individuals’ information.</li>
<li><a href="../terms/red-teaming/">red teaming</a> — Deliberate stress testing that probes AI systems for harmful, biased, or policy-violating behavior.</li>
<li><a href="../terms/responsible-ai/">responsible ai</a> — Frameworks and practices that ensure AI systems are safe, fair, and aligned with ethical and legal expectations.</li>
<li><a href="../terms/retrieval/">retrieval</a> — Process of selecting relevant documents or vectors from a corpus in response to a query.</li>
<li><a href="../terms/safety-evaluation/">safety evaluation</a> — Testing focused on preventing harmful, abusive, or policy-violating AI behavior before and after launch.</li>
<li><a href="../terms/safety-spec/">safety spec</a> — Document that codifies allowed, disallowed, and escalated behaviours for an AI system so teams can enforce safety and policy expectations.</li>
<li><a href="../terms/transparency-report/">transparency report</a> — Periodic disclosure that details how an AI system operates, what data it handles, and how risks are mitigated.</li>
<li><a href="../terms/voice-cloning/">voice cloning</a> — Technique that replicates a person’s voice using generative models trained on audio samples.</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      © 2024 AI Glossary contributors
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/san-serif-sentiments/ai-glossary" target="_blank" rel="noopener" title="GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tracking", "content.action.edit", "toc.integrate"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.bd41221c.min.js"></script>
      
    
  </body>
</html>